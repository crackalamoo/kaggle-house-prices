{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from matplotlib import pyplot as plt\n",
    "import xgboost as xgb\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>2915</td>\n",
       "      <td>160</td>\n",
       "      <td>RM</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1936</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>2916</td>\n",
       "      <td>160</td>\n",
       "      <td>RM</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1894</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>2917</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>160.0</td>\n",
       "      <td>20000</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>2918</td>\n",
       "      <td>85</td>\n",
       "      <td>RL</td>\n",
       "      <td>62.0</td>\n",
       "      <td>10441</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>Shed</td>\n",
       "      <td>700</td>\n",
       "      <td>7</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>2919</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>74.0</td>\n",
       "      <td>9627</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2919 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0        1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1        2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2        3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3        4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4        5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "...    ...         ...      ...          ...      ...    ...   ...      ...   \n",
       "1454  2915         160       RM         21.0     1936   Pave   NaN      Reg   \n",
       "1455  2916         160       RM         21.0     1894   Pave   NaN      Reg   \n",
       "1456  2917          20       RL        160.0    20000   Pave   NaN      Reg   \n",
       "1457  2918          85       RL         62.0    10441   Pave   NaN      Reg   \n",
       "1458  2919          60       RL         74.0     9627   Pave   NaN      Reg   \n",
       "\n",
       "     LandContour Utilities  ... PoolArea PoolQC  Fence MiscFeature MiscVal  \\\n",
       "0            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "1            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "2            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "3            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "4            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "...          ...       ...  ...      ...    ...    ...         ...     ...   \n",
       "1454         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "1455         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "1456         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "1457         Lvl    AllPub  ...        0    NaN  MnPrv        Shed     700   \n",
       "1458         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "\n",
       "     MoSold YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0         2   2008        WD         Normal   208500.0  \n",
       "1         5   2007        WD         Normal   181500.0  \n",
       "2         9   2008        WD         Normal   223500.0  \n",
       "3         2   2006        WD        Abnorml   140000.0  \n",
       "4        12   2008        WD         Normal   250000.0  \n",
       "...     ...    ...       ...            ...        ...  \n",
       "1454      6   2006        WD         Normal        NaN  \n",
       "1455      4   2006        WD        Abnorml        NaN  \n",
       "1456      9   2006        WD        Abnorml        NaN  \n",
       "1457      7   2006        WD         Normal        NaN  \n",
       "1458     11   2006        WD         Normal        NaN  \n",
       "\n",
       "[2919 rows x 81 columns]"
      ]
     },
     "execution_count": 701,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/train.csv\")\n",
    "test = pd.read_csv(\"data/test.csv\")\n",
    "merged = pd.concat([data, test], axis=0)\n",
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep_columns = ['Id', 'SalePrice', \n",
    "# 'OverallQual',\n",
    "#  'GrLivArea',\n",
    "#  '2ndFlrSF',\n",
    "#  'TotalBsmtSF',\n",
    "#  'BsmtFinSF1',\n",
    "#  '1stFlrSF',\n",
    "#  'LotArea',\n",
    "#  'GarageCars',\n",
    "#  'MasVnrArea',\n",
    "#  'GarageArea',\n",
    "#  'YearBuilt',\n",
    "#  'FullBath',\n",
    "#  'YearRemodAdd',\n",
    "#  'BsmtUnfSF',\n",
    "#  'LotFrontage',\n",
    "#  'KitchenQual',\n",
    "#  'BsmtQual',\n",
    "#  'GarageYrBlt',\n",
    "#  'OpenPorchSF',\n",
    "#  'WoodDeckSF',\n",
    "#  'OverallCond',\n",
    "#  'CentralAir',\n",
    "#  'LotShape',\n",
    "#  'MoSold', \n",
    "#  'YrSold',\n",
    "#  'BedroomAbvGr',\n",
    "#  'TotRmsAbvGrd',\n",
    "#  'GarageType',\n",
    "#  'Fireplaces',\n",
    "#  'ScreenPorch',\n",
    "#  'ExterQual']\n",
    "\n",
    "# merged = merged[keep_columns]\n",
    "# merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {},
   "outputs": [],
   "source": [
    "## stuff on NA columns\n",
    "\n",
    "# LotFrontage: Linear feet of street connected to property. NA=0?\n",
    "# Alley: NA = no alley\n",
    "# MasVnrType: NA = no masonry veneer\n",
    "# MasVnrArea: NA = 0\n",
    "# BsmtQual: NA = no basement\n",
    "# BsmtCond: NA = no basement\n",
    "# BsmtExposure: NA = no basement\n",
    "# BsmtFinType1: NA = no basement\n",
    "# BsmtFinType2: NA = no basement\n",
    "# Electrical: not clear, we may remove the observation\n",
    "# FireplaceQu: NA = no fireplace\n",
    "# Garage(X): NA = no garage\n",
    "# PoolQC: NA = no pool\n",
    "# Fence: NA = no fence\n",
    "# MiscFeature: NA = no misc feature\n",
    "# GarageYrBlt: NA = no garage\n",
    "\n",
    "def handle_na(df):\n",
    "    use_na = [\n",
    "        'Alley','MasVnrType','BsmtQual','BsmtCond','BsmtExposure',\n",
    "        'BsmtFinType1','BsmtFinType2','FireplaceQu','GarageType',\n",
    "        'GarageFinish','GarageQual','GarageCond','PoolQC','Fence','MiscFeature'\n",
    "    ]\n",
    "    use_0 = [\n",
    "        'LotFrontage','MasVnrArea','GarageCars','GarageArea'\n",
    "    ]\n",
    "    for key in use_na:\n",
    "        if key in df.columns:\n",
    "            df[key] = df[key].fillna('NA')\n",
    "    for key in use_0:\n",
    "        if key in df.columns:\n",
    "            df[key] = df[key].fillna(0)\n",
    "    \n",
    "    if 'Electrical' in df.columns:\n",
    "        df['Electrical'] = df['Electrical'].fillna(df['Electrical'].mode()[0])\n",
    "    if 'GarageYrBlt' in df.columns:\n",
    "        df['GarageYrBlt'] = df['GarageYrBlt'].fillna(min(df['GarageYrBlt']))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic feature engineering / processing tasks\n",
    "\n",
    "def feature_engineering(df):\n",
    "    # drop Id\n",
    "    df = df.drop(['Id'], axis=1)\n",
    "\n",
    "    # combine month sold and year sold into one column\n",
    "    df['SaleDate'] = df['MoSold']/12 + df['YrSold']\n",
    "    df = df.drop(['MoSold', 'YrSold'], axis=1)\n",
    "\n",
    "    # convert mssubclass to categorical\n",
    "    df['MSSubClass'] = df['MSSubClass'].astype(str)\n",
    "\n",
    "    # for everything that's not a numerical column, convert to categorical\n",
    "    non_numerical_cols = df.select_dtypes(exclude=np.number).columns\n",
    "    df[non_numerical_cols] = df[non_numerical_cols].astype('category')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>...</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>SaleDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NA</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>0</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500.0</td>\n",
       "      <td>2008.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NA</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>0</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500.0</td>\n",
       "      <td>2007.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NA</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>0</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500.0</td>\n",
       "      <td>2008.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NA</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>0</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000.0</td>\n",
       "      <td>2006.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NA</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>0</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000.0</td>\n",
       "      <td>2009.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>160</td>\n",
       "      <td>RM</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1936</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NA</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>0</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>160</td>\n",
       "      <td>RM</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1894</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NA</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>0</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>160.0</td>\n",
       "      <td>20000</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NA</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>0</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>85</td>\n",
       "      <td>RL</td>\n",
       "      <td>62.0</td>\n",
       "      <td>10441</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NA</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NA</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>Shed</td>\n",
       "      <td>700</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>74.0</td>\n",
       "      <td>9627</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NA</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>0</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006.916667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2919 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0            60       RL         65.0     8450   Pave    NA      Reg   \n",
       "1            20       RL         80.0     9600   Pave    NA      Reg   \n",
       "2            60       RL         68.0    11250   Pave    NA      IR1   \n",
       "3            70       RL         60.0     9550   Pave    NA      IR1   \n",
       "4            60       RL         84.0    14260   Pave    NA      IR1   \n",
       "...         ...      ...          ...      ...    ...   ...      ...   \n",
       "1454        160       RM         21.0     1936   Pave    NA      Reg   \n",
       "1455        160       RM         21.0     1894   Pave    NA      Reg   \n",
       "1456         20       RL        160.0    20000   Pave    NA      Reg   \n",
       "1457         85       RL         62.0    10441   Pave    NA      Reg   \n",
       "1458         60       RL         74.0     9627   Pave    NA      Reg   \n",
       "\n",
       "     LandContour Utilities LotConfig  ... ScreenPorch PoolArea PoolQC  Fence  \\\n",
       "0            Lvl    AllPub    Inside  ...           0        0     NA     NA   \n",
       "1            Lvl    AllPub       FR2  ...           0        0     NA     NA   \n",
       "2            Lvl    AllPub    Inside  ...           0        0     NA     NA   \n",
       "3            Lvl    AllPub    Corner  ...           0        0     NA     NA   \n",
       "4            Lvl    AllPub       FR2  ...           0        0     NA     NA   \n",
       "...          ...       ...       ...  ...         ...      ...    ...    ...   \n",
       "1454         Lvl    AllPub    Inside  ...           0        0     NA     NA   \n",
       "1455         Lvl    AllPub    Inside  ...           0        0     NA     NA   \n",
       "1456         Lvl    AllPub    Inside  ...           0        0     NA     NA   \n",
       "1457         Lvl    AllPub    Inside  ...           0        0     NA  MnPrv   \n",
       "1458         Lvl    AllPub    Inside  ...           0        0     NA     NA   \n",
       "\n",
       "     MiscFeature MiscVal  SaleType  SaleCondition  SalePrice     SaleDate  \n",
       "0             NA       0        WD         Normal   208500.0  2008.166667  \n",
       "1             NA       0        WD         Normal   181500.0  2007.416667  \n",
       "2             NA       0        WD         Normal   223500.0  2008.750000  \n",
       "3             NA       0        WD        Abnorml   140000.0  2006.166667  \n",
       "4             NA       0        WD         Normal   250000.0  2009.000000  \n",
       "...          ...     ...       ...            ...        ...          ...  \n",
       "1454          NA       0        WD         Normal        NaN  2006.500000  \n",
       "1455          NA       0        WD        Abnorml        NaN  2006.333333  \n",
       "1456          NA       0        WD        Abnorml        NaN  2006.750000  \n",
       "1457        Shed     700        WD         Normal        NaN  2006.583333  \n",
       "1458          NA       0        WD         Normal        NaN  2006.916667  \n",
       "\n",
       "[2919 rows x 79 columns]"
      ]
     },
     "execution_count": 705,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged = handle_na(merged)\n",
    "merged = feature_engineering(merged)\n",
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# # Set the plot style\n",
    "# sns.set_theme(style='whitegrid')\n",
    "\n",
    "# # Select numerical columns and plot histograms\n",
    "# numerical_cols = data.select_dtypes(include=np.number).columns\n",
    "# data[numerical_cols].hist(figsize=(12, 8), bins=20)\n",
    "\n",
    "# # Add labels and titles\n",
    "# plt.xlabel('Value')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.title('Histograms of Numerical Features')\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the categorical columns\n",
    "categorical_cols = merged.select_dtypes(include='category').columns\n",
    "\n",
    "# Perform one-hot encoding\n",
    "merged = pd.get_dummies(merged, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "data = merged.iloc[:len(data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and validation\n",
    "train, val = train_test_split(data, test_size=0.2, random_state=420)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78056.97104591088"
      ]
     },
     "execution_count": 709,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Baseline RMSE from just predicting mean\n",
    "np.sqrt(mean_squared_error(val['SalePrice'], np.mean(val['SalePrice']) * np.ones(val['SalePrice'].shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(train_pred, val_pred):\n",
    "    train_mse = mean_squared_error(train['SalePrice'], train_pred)\n",
    "    print('Train rMSE:', np.sqrt(train_mse))\n",
    "\n",
    "    val_mse = mean_squared_error(val['SalePrice'], val_pred)\n",
    "    print('Val rMSE:', np.sqrt(val_mse))\n",
    "\n",
    "def ensemble(train_preds, y_true=train['SalePrice']):\n",
    "    # Stack predictions as features for the meta-model\n",
    "    X_stack = np.column_stack(train_preds)\n",
    "    meta_model = LinearRegression()\n",
    "    meta_model.fit(X_stack, y_true)\n",
    "\n",
    "    # The weights\n",
    "    weights = meta_model.coef_\n",
    "    print(\"Weights for DR Stacking:\", weights)\n",
    "\n",
    "    # MSE CSL\n",
    "    return meta_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train rMSE: 20486.873455038494\n",
      "Val rMSE: 43455.002144091995\n"
     ]
    }
   ],
   "source": [
    "## Linear model\n",
    "lm = LinearRegression()\n",
    "lm.fit(train.drop('SalePrice', axis=1), train['SalePrice'])\n",
    "\n",
    "train_pred_lm = lm.predict(train.drop('SalePrice', axis=1))\n",
    "val_pred_lm = lm.predict(val.drop('SalePrice', axis=1))\n",
    "eval_model(train_pred_lm, val_pred_lm)\n",
    "\n",
    "### Random Forest (no hyperparameter tuning)\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(train.drop('SalePrice', axis=1), train['SalePrice'])\n",
    "\n",
    "train_pred_rf = rf.predict(train.drop('SalePrice', axis=1))\n",
    "val_pred_rf = rf.predict(val.drop('SalePrice', axis=1))\n",
    "eval_model(train_pred_rf, val_pred_rf)\n",
    "\n",
    "### Gradient boosting\n",
    "dtrain = xgb.DMatrix(train.drop('SalePrice', axis=1), label=train['SalePrice'])\n",
    "dval = xgb.DMatrix(val.drop('SalePrice', axis=1), label=val['SalePrice'])\n",
    "params = {\n",
    "        'booster': 'gbtree',\n",
    "        'subsample': 1.0,\n",
    "        'colsample_bytree': 0.9,\n",
    "        'num_parallel_tree': 1,\n",
    "        'max_depth': 7,\n",
    "        'min_child_weight': 7,\n",
    "        'eta': 0.1,\n",
    "        'gamma': 0.05,\n",
    "        # 'lambda': 2,\n",
    "        'random_state': 195,\n",
    "    }\n",
    "# Specify validations set to watch performance\n",
    "results = {}\n",
    "watchlist = [(dtrain, 'train'), (dval, 'eval')]\n",
    "bst = xgb.train(params=params, dtrain=dtrain, num_boost_round=100, evals=watchlist, evals_result = results, early_stopping_rounds=10, verbose_eval=False)\n",
    "# Assuming dtest is already defined and is the test DMatrix\n",
    "train_pred_gb = bst.predict(dtrain)\n",
    "val_pred_gb = bst.predict(dval)\n",
    "eval_model(train_pred_gb, val_pred_gb)\n",
    "\n",
    "### Stacking\n",
    "train_preds = [train_pred_rf, train_pred_gb]\n",
    "val_preds = [val_pred_rf, val_pred_gb]\n",
    "ensemble_model = ensemble(train_preds)\n",
    "train_pred_stack, val_pred_stack = ensemble_model.predict(np.column_stack(train_preds)), ensemble_model.predict(np.column_stack(val_preds))\n",
    "eval_model(train_pred_stack, val_pred_stack)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuning the RF and GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### perform k=5 fold cross validation on random forest, doing grid search over hyperparameters\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# rf_param_grid = {\n",
    "#     'max_depth': [5, 10, 20],\n",
    "#     'min_samples_split': [2, 5, 10, 20, 50],\n",
    "#     'min_samples_leaf': [2, 5, 10, 20, 50],\n",
    "# }\n",
    "# rf = RandomForestRegressor(n_estimators=50, random_state=0)\n",
    "# grid_search = GridSearchCV(estimator=rf, param_grid=rf_param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "# grid_search.fit(data.drop('SalePrice', axis=1), data['SalePrice'])\n",
    "# print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[699], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m rf_params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m20\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin_samples_leaf\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin_samples_split\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m10\u001b[39m} \u001b[38;5;66;03m### seems like default rf does better\u001b[39;00m\n\u001b[1;32m      2\u001b[0m rf \u001b[38;5;241m=\u001b[39m RandomForestRegressor(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mrf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSalePrice\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSalePrice\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m train_pred_rf \u001b[38;5;241m=\u001b[39m rf\u001b[38;5;241m.\u001b[39mpredict(train\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSalePrice\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m      5\u001b[0m val_pred_rf \u001b[38;5;241m=\u001b[39m rf\u001b[38;5;241m.\u001b[39mpredict(val\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSalePrice\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:1351\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1344\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1347\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1348\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1349\u001b[0m     )\n\u001b[1;32m   1350\u001b[0m ):\n\u001b[0;32m-> 1351\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/ensemble/_forest.py:489\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    478\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    481\u001b[0m ]\n\u001b[1;32m    483\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 489\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    506\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    507\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     66\u001b[0m )\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/joblib/parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/joblib/parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/parallel.py:129\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/ensemble/_forest.py:192\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    190\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[0;32m--> 192\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    200\u001b[0m     tree\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[1;32m    201\u001b[0m         X,\n\u001b[1;32m    202\u001b[0m         y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    205\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[1;32m    206\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/tree/_classes.py:472\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[0;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    462\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    463\u001b[0m         splitter,\n\u001b[1;32m    464\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    470\u001b[0m     )\n\u001b[0;32m--> 472\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    475\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rf_params = {'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 10} ### seems like default rf does better\n",
    "rf = RandomForestRegressor(n_estimators=50, random_state=0)\n",
    "rf.fit(train.drop('SalePrice', axis=1), train['SalePrice'])\n",
    "train_pred_rf = rf.predict(train.drop('SalePrice', axis=1))\n",
    "val_pred_rf = rf.predict(val.drop('SalePrice', axis=1))\n",
    "eval_model(train_pred_rf, val_pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### perform k=5 fold cross validation on xgboost, doing grid search over hyperparameters\n",
    "# ddata = xgb.DMatrix(data.drop('SalePrice', axis=1), label=data['SalePrice'])\n",
    "\n",
    "# gb_param_grid = {\n",
    "#     'max_depth': [3, 5, 7, 10],\n",
    "#     'eta': [0.01, 0.015, 0.025, 0.05, 0.1], \n",
    "#     'gamma': [0.05, 0.3, 0.5, 0.7, 1.0],\n",
    "#     'subsample': [0.5, 0.7, 0.9, 1.0],\n",
    "#     'colsample_bytree': [0.5, 0.7, 0.9, 1.0],\n",
    "#     'min_child_weight': [1, 3, 5, 7]\n",
    "# }\n",
    "\n",
    "\n",
    "# ### First optimize eta, gamma, min_child_weight\n",
    "# params = {\n",
    "#     'booster': 'gbtree',\n",
    "#     'num_parallel_tree': 1,\n",
    "#     'random_state': 0,\n",
    "# }\n",
    "\n",
    "# from itertools import product\n",
    "\n",
    "# best_params = None\n",
    "# min_mse = float('inf')\n",
    "\n",
    "# i = 0\n",
    "# for eta, gamma, min_child_weight in product(gb_param_grid['eta'], gb_param_grid['gamma'], gb_param_grid['min_child_weight']):\n",
    "#     if i % 10 == 0:\n",
    "#         print(i)\n",
    "#         print(min_mse)\n",
    "\n",
    "#     params['eta'] = eta\n",
    "#     params['gamma'] = gamma\n",
    "#     params['min_child_weight'] = min_child_weight\n",
    "\n",
    "#     res = xgb.cv(\n",
    "#         params,\n",
    "#         ddata,\n",
    "#         num_boost_round=100,\n",
    "#         nfold=5,\n",
    "#         seed=0,\n",
    "#     )\n",
    "#     mse = res[\"test-rmse-mean\"].values[-1]\n",
    "\n",
    "#     if mse < min_mse:\n",
    "#         min_mse = mse\n",
    "#         best_params = {'eta':eta, 'gamma': gamma, 'min_child_weight': min_child_weight}\n",
    "#     i += 1\n",
    "\n",
    "# print(\"Best Params:\", best_params)\n",
    "\n",
    "\n",
    "# ### Next optimize max_depth, subsample, colsample_bytree\n",
    "# params = {\n",
    "#     'booster': 'gbtree',\n",
    "#     'num_parallel_tree': 1,\n",
    "#     'random_state': 0,\n",
    "#     'eta': 0.1,\n",
    "#     'gamma': 0.05,\n",
    "#     'min_child_weight': 3\n",
    "# }\n",
    "\n",
    "# best_params = None\n",
    "# min_mse = float('inf')\n",
    "\n",
    "# i = 0\n",
    "\n",
    "# for max_depth, subsample, colsample in product(gb_param_grid['max_depth'], gb_param_grid['subsample'], gb_param_grid['colsample_bytree']):\n",
    "#     if i % 10 == 0:\n",
    "#         print(i)\n",
    "#         print(min_mse)\n",
    "\n",
    "#     params['max_depth'] = max_depth\n",
    "#     params['subsample'] = subsample\n",
    "#     params['colsample_bytree'] = colsample\n",
    "\n",
    "#     res = xgb.cv(\n",
    "#         params,\n",
    "#         ddata,\n",
    "#         num_boost_round=100,\n",
    "#         nfold=5,\n",
    "#         seed=0,\n",
    "#     )\n",
    "#     mse = res[\"test-rmse-mean\"].values[-1]\n",
    "\n",
    "#     if mse < min_mse:\n",
    "#         min_mse = mse\n",
    "#         best_params = {'max_depth':max_depth, 'subsample': subsample, 'colsample_bytree': colsample}\n",
    "#     i += 1\n",
    "\n",
    "# print(\"Best Params:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train rMSE: 4717.767920545617\n",
      "Val rMSE: 23381.180898343693\n"
     ]
    }
   ],
   "source": [
    "### final GB model\n",
    "gb_params = {\n",
    "    'booster': 'gbtree',\n",
    "    'num_parallel_tree': 10,\n",
    "    'random_state': 0,\n",
    "    'eta': 0.05,\n",
    "    'gamma': 0.05,\n",
    "    'min_child_weight': 3,\n",
    "    'max_depth': 7,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8\n",
    "}\n",
    "# Specify validations set to watch performance\n",
    "results = {}\n",
    "watchlist = [(dtrain, 'train'), (dval, 'eval')]\n",
    "gb = xgb.train(params=gb_params, dtrain=dtrain, num_boost_round=1000, evals=watchlist, evals_result = results, early_stopping_rounds=10, verbose_eval=False)\n",
    "# Assuming dtest is already defined and is the test DMatrix\n",
    "train_pred_gb = gb.predict(dtrain)\n",
    "val_pred_gb = gb.predict(dval)\n",
    "eval_model(train_pred_gb, val_pred_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### train a 2 hidden layer mlp\n",
    "# from sklearn.neural_network import MLPRegressor\n",
    "# mlp = MLPRegressor(hidden_layer_sizes=(100, 100), max_iter=1000, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights for DR Stacking: [-0.11958517  1.12311618]\n",
      "Train rMSE: 4542.711309074991\n",
      "Val rMSE: 23337.044597058237\n"
     ]
    }
   ],
   "source": [
    "### Stacking\n",
    "train_preds = [train_pred_rf, train_pred_gb]\n",
    "val_preds = [val_pred_rf, val_pred_gb]\n",
    "ensemble_model = ensemble(train_preds)\n",
    "train_pred_stack, val_pred_stack = ensemble_model.predict(np.column_stack(train_preds)), ensemble_model.predict(np.column_stack(val_preds))\n",
    "eval_model(train_pred_stack, val_pred_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:76155.03545\teval-rmse:76155.03545\n",
      "[1]\ttrain-rmse:73051.15938\teval-rmse:73051.15938\n",
      "[2]\ttrain-rmse:70111.44335\teval-rmse:70111.44335\n",
      "[3]\ttrain-rmse:67291.14353\teval-rmse:67291.14353\n",
      "[4]\ttrain-rmse:64609.32817\teval-rmse:64609.32817\n",
      "[5]\ttrain-rmse:62033.24341\teval-rmse:62033.24341\n",
      "[6]\ttrain-rmse:59590.19575\teval-rmse:59590.19575\n",
      "[7]\ttrain-rmse:57259.14588\teval-rmse:57259.14588\n",
      "[8]\ttrain-rmse:55060.15895\teval-rmse:55060.15895\n",
      "[9]\ttrain-rmse:52931.28823\teval-rmse:52931.28823\n",
      "[10]\ttrain-rmse:50922.49896\teval-rmse:50922.49896\n",
      "[11]\ttrain-rmse:48984.84067\teval-rmse:48984.84067\n",
      "[12]\ttrain-rmse:47139.77485\teval-rmse:47139.77485\n",
      "[13]\ttrain-rmse:45383.86146\teval-rmse:45383.86146\n",
      "[14]\ttrain-rmse:43699.85129\teval-rmse:43699.85129\n",
      "[15]\ttrain-rmse:42097.48644\teval-rmse:42097.48644\n",
      "[16]\ttrain-rmse:40574.70060\teval-rmse:40574.70060\n",
      "[17]\ttrain-rmse:39114.94258\teval-rmse:39114.94258\n",
      "[18]\ttrain-rmse:37719.25227\teval-rmse:37719.25227\n",
      "[19]\ttrain-rmse:36398.63509\teval-rmse:36398.63509\n",
      "[20]\ttrain-rmse:35104.68866\teval-rmse:35104.68866\n",
      "[21]\ttrain-rmse:33897.20993\teval-rmse:33897.20993\n",
      "[22]\ttrain-rmse:32726.04099\teval-rmse:32726.04099\n",
      "[23]\ttrain-rmse:31611.38361\teval-rmse:31611.38361\n",
      "[24]\ttrain-rmse:30552.46518\teval-rmse:30552.46518\n",
      "[25]\ttrain-rmse:29537.56924\teval-rmse:29537.56924\n",
      "[26]\ttrain-rmse:28566.50135\teval-rmse:28566.50135\n",
      "[27]\ttrain-rmse:27636.99268\teval-rmse:27636.99268\n",
      "[28]\ttrain-rmse:26743.49422\teval-rmse:26743.49422\n",
      "[29]\ttrain-rmse:25900.90120\teval-rmse:25900.90120\n",
      "[30]\ttrain-rmse:25091.65714\teval-rmse:25091.65714\n",
      "[31]\ttrain-rmse:24327.00215\teval-rmse:24327.00215\n",
      "[32]\ttrain-rmse:23598.45189\teval-rmse:23598.45189\n",
      "[33]\ttrain-rmse:22896.28435\teval-rmse:22896.28435\n",
      "[34]\ttrain-rmse:22230.49714\teval-rmse:22230.49714\n",
      "[35]\ttrain-rmse:21587.32114\teval-rmse:21587.32114\n",
      "[36]\ttrain-rmse:20966.02469\teval-rmse:20966.02469\n",
      "[37]\ttrain-rmse:20382.53648\teval-rmse:20382.53648\n",
      "[38]\ttrain-rmse:19816.12005\teval-rmse:19816.12005\n",
      "[39]\ttrain-rmse:19276.24353\teval-rmse:19276.24353\n",
      "[40]\ttrain-rmse:18760.70331\teval-rmse:18760.70331\n",
      "[41]\ttrain-rmse:18276.73199\teval-rmse:18276.73199\n",
      "[42]\ttrain-rmse:17818.25367\teval-rmse:17818.25367\n",
      "[43]\ttrain-rmse:17374.88307\teval-rmse:17374.88307\n",
      "[44]\ttrain-rmse:16942.66185\teval-rmse:16942.66185\n",
      "[45]\ttrain-rmse:16532.69526\teval-rmse:16532.69526\n",
      "[46]\ttrain-rmse:16142.00330\teval-rmse:16142.00330\n",
      "[47]\ttrain-rmse:15758.19987\teval-rmse:15758.19987\n",
      "[48]\ttrain-rmse:15405.91451\teval-rmse:15405.91451\n",
      "[49]\ttrain-rmse:15064.97064\teval-rmse:15064.97064\n",
      "[50]\ttrain-rmse:14731.96743\teval-rmse:14731.96743\n",
      "[51]\ttrain-rmse:14416.09934\teval-rmse:14416.09934\n",
      "[52]\ttrain-rmse:14112.13413\teval-rmse:14112.13413\n",
      "[53]\ttrain-rmse:13821.74184\teval-rmse:13821.74184\n",
      "[54]\ttrain-rmse:13546.74369\teval-rmse:13546.74369\n",
      "[55]\ttrain-rmse:13277.40959\teval-rmse:13277.40959\n",
      "[56]\ttrain-rmse:13020.89675\teval-rmse:13020.89675\n",
      "[57]\ttrain-rmse:12770.53564\teval-rmse:12770.53564\n",
      "[58]\ttrain-rmse:12530.71585\teval-rmse:12530.71585\n",
      "[59]\ttrain-rmse:12302.95448\teval-rmse:12302.95448\n",
      "[60]\ttrain-rmse:12090.75282\teval-rmse:12090.75282\n",
      "[61]\ttrain-rmse:11886.45941\teval-rmse:11886.45941\n",
      "[62]\ttrain-rmse:11691.97337\teval-rmse:11691.97337\n",
      "[63]\ttrain-rmse:11500.58029\teval-rmse:11500.58029\n",
      "[64]\ttrain-rmse:11318.14303\teval-rmse:11318.14303\n",
      "[65]\ttrain-rmse:11146.48269\teval-rmse:11146.48269\n",
      "[66]\ttrain-rmse:10975.19184\teval-rmse:10975.19184\n",
      "[67]\ttrain-rmse:10810.92525\teval-rmse:10810.92525\n",
      "[68]\ttrain-rmse:10659.71112\teval-rmse:10659.71112\n",
      "[69]\ttrain-rmse:10510.13638\teval-rmse:10510.13638\n",
      "[70]\ttrain-rmse:10367.63568\teval-rmse:10367.63568\n",
      "[71]\ttrain-rmse:10230.52847\teval-rmse:10230.52847\n",
      "[72]\ttrain-rmse:10099.54494\teval-rmse:10099.54494\n",
      "[73]\ttrain-rmse:9968.27287\teval-rmse:9968.27287\n",
      "[74]\ttrain-rmse:9844.01270\teval-rmse:9844.01270\n",
      "[75]\ttrain-rmse:9730.46337\teval-rmse:9730.46337\n",
      "[76]\ttrain-rmse:9609.48531\teval-rmse:9609.48531\n",
      "[77]\ttrain-rmse:9502.63147\teval-rmse:9502.63147\n",
      "[78]\ttrain-rmse:9396.71847\teval-rmse:9396.71847\n",
      "[79]\ttrain-rmse:9295.76654\teval-rmse:9295.76654\n",
      "[80]\ttrain-rmse:9196.13394\teval-rmse:9196.13394\n",
      "[81]\ttrain-rmse:9099.24588\teval-rmse:9099.24588\n",
      "[82]\ttrain-rmse:9006.82254\teval-rmse:9006.82254\n",
      "[83]\ttrain-rmse:8926.05601\teval-rmse:8926.05601\n",
      "[84]\ttrain-rmse:8841.21074\teval-rmse:8841.21074\n",
      "[85]\ttrain-rmse:8763.36844\teval-rmse:8763.36844\n",
      "[86]\ttrain-rmse:8685.52315\teval-rmse:8685.52315\n",
      "[87]\ttrain-rmse:8607.52278\teval-rmse:8607.52278\n",
      "[88]\ttrain-rmse:8535.08031\teval-rmse:8535.08031\n",
      "[89]\ttrain-rmse:8467.94015\teval-rmse:8467.94015\n",
      "[90]\ttrain-rmse:8399.93207\teval-rmse:8399.93207\n",
      "[91]\ttrain-rmse:8331.44246\teval-rmse:8331.44246\n",
      "[92]\ttrain-rmse:8267.21700\teval-rmse:8267.21700\n",
      "[93]\ttrain-rmse:8208.85646\teval-rmse:8208.85646\n",
      "[94]\ttrain-rmse:8151.53947\teval-rmse:8151.53947\n",
      "[95]\ttrain-rmse:8090.25168\teval-rmse:8090.25168\n",
      "[96]\ttrain-rmse:8033.13371\teval-rmse:8033.13371\n",
      "[97]\ttrain-rmse:7982.47230\teval-rmse:7982.47230\n",
      "[98]\ttrain-rmse:7928.35232\teval-rmse:7928.35232\n",
      "[99]\ttrain-rmse:7877.25696\teval-rmse:7877.25696\n",
      "[100]\ttrain-rmse:7828.14560\teval-rmse:7828.14560\n",
      "[101]\ttrain-rmse:7785.17259\teval-rmse:7785.17259\n",
      "[102]\ttrain-rmse:7737.42071\teval-rmse:7737.42071\n",
      "[103]\ttrain-rmse:7690.64844\teval-rmse:7690.64844\n",
      "[104]\ttrain-rmse:7647.66009\teval-rmse:7647.66009\n",
      "[105]\ttrain-rmse:7603.69083\teval-rmse:7603.69083\n",
      "[106]\ttrain-rmse:7560.68799\teval-rmse:7560.68799\n",
      "[107]\ttrain-rmse:7516.13681\teval-rmse:7516.13681\n",
      "[108]\ttrain-rmse:7477.90749\teval-rmse:7477.90749\n",
      "[109]\ttrain-rmse:7438.59376\teval-rmse:7438.59376\n",
      "[110]\ttrain-rmse:7402.26753\teval-rmse:7402.26753\n",
      "[111]\ttrain-rmse:7370.06804\teval-rmse:7370.06804\n",
      "[112]\ttrain-rmse:7330.95311\teval-rmse:7330.95311\n",
      "[113]\ttrain-rmse:7296.60916\teval-rmse:7296.60916\n",
      "[114]\ttrain-rmse:7254.46599\teval-rmse:7254.46599\n",
      "[115]\ttrain-rmse:7219.31351\teval-rmse:7219.31351\n",
      "[116]\ttrain-rmse:7182.78541\teval-rmse:7182.78541\n",
      "[117]\ttrain-rmse:7148.37985\teval-rmse:7148.37985\n",
      "[118]\ttrain-rmse:7111.16528\teval-rmse:7111.16528\n",
      "[119]\ttrain-rmse:7080.81429\teval-rmse:7080.81429\n",
      "[120]\ttrain-rmse:7050.36450\teval-rmse:7050.36450\n",
      "[121]\ttrain-rmse:7020.09622\teval-rmse:7020.09622\n",
      "[122]\ttrain-rmse:6991.25348\teval-rmse:6991.25348\n",
      "[123]\ttrain-rmse:6961.31719\teval-rmse:6961.31719\n",
      "[124]\ttrain-rmse:6931.13538\teval-rmse:6931.13538\n",
      "[125]\ttrain-rmse:6898.22035\teval-rmse:6898.22035\n",
      "[126]\ttrain-rmse:6866.01053\teval-rmse:6866.01053\n",
      "[127]\ttrain-rmse:6837.61347\teval-rmse:6837.61347\n",
      "[128]\ttrain-rmse:6809.16885\teval-rmse:6809.16885\n",
      "[129]\ttrain-rmse:6782.61444\teval-rmse:6782.61444\n",
      "[130]\ttrain-rmse:6755.45107\teval-rmse:6755.45107\n",
      "[131]\ttrain-rmse:6726.15435\teval-rmse:6726.15435\n",
      "[132]\ttrain-rmse:6701.23139\teval-rmse:6701.23139\n",
      "[133]\ttrain-rmse:6673.21362\teval-rmse:6673.21362\n",
      "[134]\ttrain-rmse:6649.85105\teval-rmse:6649.85105\n",
      "[135]\ttrain-rmse:6624.06482\teval-rmse:6624.06482\n",
      "[136]\ttrain-rmse:6596.75023\teval-rmse:6596.75023\n",
      "[137]\ttrain-rmse:6570.61302\teval-rmse:6570.61302\n",
      "[138]\ttrain-rmse:6546.48016\teval-rmse:6546.48016\n",
      "[139]\ttrain-rmse:6518.41287\teval-rmse:6518.41287\n",
      "[140]\ttrain-rmse:6492.19844\teval-rmse:6492.19844\n",
      "[141]\ttrain-rmse:6468.89872\teval-rmse:6468.89872\n",
      "[142]\ttrain-rmse:6443.32743\teval-rmse:6443.32743\n",
      "[143]\ttrain-rmse:6419.92111\teval-rmse:6419.92111\n",
      "[144]\ttrain-rmse:6393.76384\teval-rmse:6393.76384\n",
      "[145]\ttrain-rmse:6370.86005\teval-rmse:6370.86005\n",
      "[146]\ttrain-rmse:6348.24919\teval-rmse:6348.24919\n",
      "[147]\ttrain-rmse:6322.81530\teval-rmse:6322.81530\n",
      "[148]\ttrain-rmse:6299.07961\teval-rmse:6299.07961\n",
      "[149]\ttrain-rmse:6273.40731\teval-rmse:6273.40731\n",
      "[150]\ttrain-rmse:6247.92402\teval-rmse:6247.92402\n",
      "[151]\ttrain-rmse:6225.60277\teval-rmse:6225.60277\n",
      "[152]\ttrain-rmse:6200.02406\teval-rmse:6200.02406\n",
      "[153]\ttrain-rmse:6176.82430\teval-rmse:6176.82430\n",
      "[154]\ttrain-rmse:6153.62316\teval-rmse:6153.62316\n",
      "[155]\ttrain-rmse:6130.99748\teval-rmse:6130.99748\n",
      "[156]\ttrain-rmse:6106.68233\teval-rmse:6106.68233\n",
      "[157]\ttrain-rmse:6083.53437\teval-rmse:6083.53437\n",
      "[158]\ttrain-rmse:6060.82998\teval-rmse:6060.82998\n",
      "[159]\ttrain-rmse:6037.59647\teval-rmse:6037.59647\n",
      "[160]\ttrain-rmse:6016.88683\teval-rmse:6016.88683\n",
      "[161]\ttrain-rmse:5992.76684\teval-rmse:5992.76684\n",
      "[162]\ttrain-rmse:5972.89667\teval-rmse:5972.89667\n",
      "[163]\ttrain-rmse:5949.17686\teval-rmse:5949.17686\n",
      "[164]\ttrain-rmse:5925.96909\teval-rmse:5925.96909\n",
      "[165]\ttrain-rmse:5902.23881\teval-rmse:5902.23881\n",
      "[166]\ttrain-rmse:5876.42024\teval-rmse:5876.42024\n",
      "[167]\ttrain-rmse:5853.27502\teval-rmse:5853.27502\n",
      "[168]\ttrain-rmse:5831.44235\teval-rmse:5831.44235\n",
      "[169]\ttrain-rmse:5808.09624\teval-rmse:5808.09624\n",
      "[170]\ttrain-rmse:5784.41744\teval-rmse:5784.41744\n",
      "[171]\ttrain-rmse:5760.35779\teval-rmse:5760.35779\n",
      "[172]\ttrain-rmse:5736.58696\teval-rmse:5736.58696\n",
      "[173]\ttrain-rmse:5713.90016\teval-rmse:5713.90016\n",
      "[174]\ttrain-rmse:5691.86926\teval-rmse:5691.86926\n",
      "[175]\ttrain-rmse:5670.24346\teval-rmse:5670.24346\n",
      "[176]\ttrain-rmse:5649.79117\teval-rmse:5649.79117\n",
      "[177]\ttrain-rmse:5625.86497\teval-rmse:5625.86497\n",
      "[178]\ttrain-rmse:5601.32709\teval-rmse:5601.32709\n",
      "[179]\ttrain-rmse:5580.02336\teval-rmse:5580.02336\n",
      "[180]\ttrain-rmse:5556.01373\teval-rmse:5556.01373\n",
      "[181]\ttrain-rmse:5535.44722\teval-rmse:5535.44722\n",
      "[182]\ttrain-rmse:5515.78799\teval-rmse:5515.78799\n",
      "[183]\ttrain-rmse:5494.07839\teval-rmse:5494.07839\n",
      "[184]\ttrain-rmse:5471.52150\teval-rmse:5471.52150\n",
      "[185]\ttrain-rmse:5451.38145\teval-rmse:5451.38145\n",
      "[186]\ttrain-rmse:5426.20174\teval-rmse:5426.20174\n",
      "[187]\ttrain-rmse:5407.16953\teval-rmse:5407.16953\n",
      "[188]\ttrain-rmse:5381.73656\teval-rmse:5381.73656\n",
      "[189]\ttrain-rmse:5357.08894\teval-rmse:5357.08894\n",
      "[190]\ttrain-rmse:5334.68478\teval-rmse:5334.68478\n",
      "[191]\ttrain-rmse:5310.29599\teval-rmse:5310.29599\n",
      "[192]\ttrain-rmse:5286.37235\teval-rmse:5286.37235\n",
      "[193]\ttrain-rmse:5261.29234\teval-rmse:5261.29234\n",
      "[194]\ttrain-rmse:5242.03153\teval-rmse:5242.03153\n",
      "[195]\ttrain-rmse:5217.32125\teval-rmse:5217.32125\n",
      "[196]\ttrain-rmse:5194.66688\teval-rmse:5194.66688\n",
      "[197]\ttrain-rmse:5172.80419\teval-rmse:5172.80419\n",
      "[198]\ttrain-rmse:5148.63940\teval-rmse:5148.63940\n",
      "[199]\ttrain-rmse:5123.47864\teval-rmse:5123.47864\n",
      "[200]\ttrain-rmse:5099.52992\teval-rmse:5099.52992\n",
      "[201]\ttrain-rmse:5074.69672\teval-rmse:5074.69672\n",
      "[202]\ttrain-rmse:5053.23960\teval-rmse:5053.23960\n",
      "[203]\ttrain-rmse:5028.13322\teval-rmse:5028.13322\n",
      "[204]\ttrain-rmse:5004.85330\teval-rmse:5004.85330\n",
      "[205]\ttrain-rmse:4981.97920\teval-rmse:4981.97920\n",
      "[206]\ttrain-rmse:4959.18656\teval-rmse:4959.18656\n",
      "[207]\ttrain-rmse:4934.51531\teval-rmse:4934.51531\n",
      "[208]\ttrain-rmse:4911.08318\teval-rmse:4911.08318\n",
      "[209]\ttrain-rmse:4885.04936\teval-rmse:4885.04936\n",
      "[210]\ttrain-rmse:4865.61405\teval-rmse:4865.61405\n",
      "[211]\ttrain-rmse:4840.91047\teval-rmse:4840.91047\n",
      "[212]\ttrain-rmse:4818.17089\teval-rmse:4818.17089\n",
      "[213]\ttrain-rmse:4795.17712\teval-rmse:4795.17712\n",
      "[214]\ttrain-rmse:4773.27819\teval-rmse:4773.27819\n",
      "[215]\ttrain-rmse:4752.39250\teval-rmse:4752.39250\n",
      "[216]\ttrain-rmse:4726.77097\teval-rmse:4726.77097\n",
      "[217]\ttrain-rmse:4704.47042\teval-rmse:4704.47042\n",
      "[218]\ttrain-rmse:4681.67382\teval-rmse:4681.67382\n",
      "[219]\ttrain-rmse:4656.25176\teval-rmse:4656.25176\n",
      "[220]\ttrain-rmse:4631.73901\teval-rmse:4631.73901\n",
      "[221]\ttrain-rmse:4609.42568\teval-rmse:4609.42568\n",
      "[222]\ttrain-rmse:4585.65659\teval-rmse:4585.65659\n",
      "[223]\ttrain-rmse:4559.39711\teval-rmse:4559.39711\n",
      "[224]\ttrain-rmse:4536.78240\teval-rmse:4536.78240\n",
      "[225]\ttrain-rmse:4515.26958\teval-rmse:4515.26958\n",
      "[226]\ttrain-rmse:4489.67960\teval-rmse:4489.67960\n",
      "[227]\ttrain-rmse:4467.81498\teval-rmse:4467.81498\n",
      "[228]\ttrain-rmse:4444.01723\teval-rmse:4444.01723\n",
      "[229]\ttrain-rmse:4422.27105\teval-rmse:4422.27105\n",
      "[230]\ttrain-rmse:4402.76800\teval-rmse:4402.76800\n",
      "[231]\ttrain-rmse:4383.11924\teval-rmse:4383.11924\n",
      "[232]\ttrain-rmse:4361.40512\teval-rmse:4361.40512\n",
      "[233]\ttrain-rmse:4338.96114\teval-rmse:4338.96114\n",
      "[234]\ttrain-rmse:4319.27183\teval-rmse:4319.27183\n",
      "[235]\ttrain-rmse:4294.68665\teval-rmse:4294.68665\n",
      "[236]\ttrain-rmse:4270.20853\teval-rmse:4270.20853\n",
      "[237]\ttrain-rmse:4249.23631\teval-rmse:4249.23631\n",
      "[238]\ttrain-rmse:4226.30335\teval-rmse:4226.30335\n",
      "[239]\ttrain-rmse:4206.01545\teval-rmse:4206.01545\n",
      "[240]\ttrain-rmse:4182.44190\teval-rmse:4182.44190\n",
      "[241]\ttrain-rmse:4160.00726\teval-rmse:4160.00726\n",
      "[242]\ttrain-rmse:4137.62027\teval-rmse:4137.62027\n",
      "[243]\ttrain-rmse:4113.43886\teval-rmse:4113.43886\n",
      "[244]\ttrain-rmse:4091.68021\teval-rmse:4091.68021\n",
      "[245]\ttrain-rmse:4067.28938\teval-rmse:4067.28938\n",
      "[246]\ttrain-rmse:4048.60403\teval-rmse:4048.60403\n",
      "[247]\ttrain-rmse:4029.97792\teval-rmse:4029.97792\n",
      "[248]\ttrain-rmse:4010.12295\teval-rmse:4010.12295\n",
      "[249]\ttrain-rmse:3988.75991\teval-rmse:3988.75991\n",
      "[250]\ttrain-rmse:3967.65673\teval-rmse:3967.65673\n",
      "[251]\ttrain-rmse:3948.07928\teval-rmse:3948.07928\n",
      "[252]\ttrain-rmse:3929.86463\teval-rmse:3929.86463\n",
      "[253]\ttrain-rmse:3911.50044\teval-rmse:3911.50044\n",
      "[254]\ttrain-rmse:3889.28021\teval-rmse:3889.28021\n",
      "[255]\ttrain-rmse:3867.75606\teval-rmse:3867.75606\n",
      "[256]\ttrain-rmse:3850.72181\teval-rmse:3850.72181\n",
      "[257]\ttrain-rmse:3829.94827\teval-rmse:3829.94827\n",
      "[258]\ttrain-rmse:3809.88583\teval-rmse:3809.88583\n",
      "[259]\ttrain-rmse:3790.61858\teval-rmse:3790.61858\n",
      "[260]\ttrain-rmse:3771.35041\teval-rmse:3771.35041\n",
      "[261]\ttrain-rmse:3752.90107\teval-rmse:3752.90107\n",
      "[262]\ttrain-rmse:3732.76571\teval-rmse:3732.76571\n",
      "[263]\ttrain-rmse:3713.28497\teval-rmse:3713.28497\n",
      "[264]\ttrain-rmse:3691.78434\teval-rmse:3691.78434\n",
      "[265]\ttrain-rmse:3674.89574\teval-rmse:3674.89574\n",
      "[266]\ttrain-rmse:3657.92039\teval-rmse:3657.92039\n",
      "[267]\ttrain-rmse:3643.17197\teval-rmse:3643.17197\n",
      "[268]\ttrain-rmse:3623.69373\teval-rmse:3623.69373\n",
      "[269]\ttrain-rmse:3606.52699\teval-rmse:3606.52699\n",
      "[270]\ttrain-rmse:3587.36355\teval-rmse:3587.36355\n",
      "[271]\ttrain-rmse:3569.79994\teval-rmse:3569.79994\n",
      "[272]\ttrain-rmse:3552.52960\teval-rmse:3552.52960\n",
      "[273]\ttrain-rmse:3534.04356\teval-rmse:3534.04356\n",
      "[274]\ttrain-rmse:3514.89505\teval-rmse:3514.89505\n",
      "[275]\ttrain-rmse:3497.34219\teval-rmse:3497.34219\n",
      "[276]\ttrain-rmse:3478.80783\teval-rmse:3478.80783\n",
      "[277]\ttrain-rmse:3461.31943\teval-rmse:3461.31943\n",
      "[278]\ttrain-rmse:3444.72628\teval-rmse:3444.72628\n",
      "[279]\ttrain-rmse:3426.22567\teval-rmse:3426.22567\n",
      "[280]\ttrain-rmse:3407.74403\teval-rmse:3407.74403\n",
      "[281]\ttrain-rmse:3390.89191\teval-rmse:3390.89191\n",
      "[282]\ttrain-rmse:3372.95314\teval-rmse:3372.95314\n",
      "[283]\ttrain-rmse:3355.48571\teval-rmse:3355.48571\n",
      "[284]\ttrain-rmse:3336.36396\teval-rmse:3336.36396\n",
      "[285]\ttrain-rmse:3320.80681\teval-rmse:3320.80681\n",
      "[286]\ttrain-rmse:3301.38400\teval-rmse:3301.38400\n",
      "[287]\ttrain-rmse:3283.18250\teval-rmse:3283.18250\n",
      "[288]\ttrain-rmse:3267.79727\teval-rmse:3267.79727\n",
      "[289]\ttrain-rmse:3251.11999\teval-rmse:3251.11999\n",
      "[290]\ttrain-rmse:3232.79106\teval-rmse:3232.79106\n",
      "[291]\ttrain-rmse:3214.30929\teval-rmse:3214.30929\n",
      "[292]\ttrain-rmse:3197.33493\teval-rmse:3197.33493\n",
      "[293]\ttrain-rmse:3179.08025\teval-rmse:3179.08025\n",
      "[294]\ttrain-rmse:3159.74624\teval-rmse:3159.74624\n",
      "[295]\ttrain-rmse:3140.97292\teval-rmse:3140.97292\n",
      "[296]\ttrain-rmse:3125.26810\teval-rmse:3125.26810\n",
      "[297]\ttrain-rmse:3108.34450\teval-rmse:3108.34450\n",
      "[298]\ttrain-rmse:3091.00431\teval-rmse:3091.00431\n",
      "[299]\ttrain-rmse:3075.56126\teval-rmse:3075.56126\n",
      "[300]\ttrain-rmse:3058.68052\teval-rmse:3058.68052\n",
      "[301]\ttrain-rmse:3040.60161\teval-rmse:3040.60161\n",
      "[302]\ttrain-rmse:3024.30322\teval-rmse:3024.30322\n",
      "[303]\ttrain-rmse:3010.58673\teval-rmse:3010.58673\n",
      "[304]\ttrain-rmse:2995.31433\teval-rmse:2995.31433\n",
      "[305]\ttrain-rmse:2981.73186\teval-rmse:2981.73186\n",
      "[306]\ttrain-rmse:2966.34867\teval-rmse:2966.34867\n",
      "[307]\ttrain-rmse:2949.81486\teval-rmse:2949.81486\n",
      "[308]\ttrain-rmse:2935.22994\teval-rmse:2935.22994\n",
      "[309]\ttrain-rmse:2919.26756\teval-rmse:2919.26756\n",
      "[310]\ttrain-rmse:2904.07757\teval-rmse:2904.07757\n",
      "[311]\ttrain-rmse:2890.25739\teval-rmse:2890.25739\n",
      "[312]\ttrain-rmse:2875.97262\teval-rmse:2875.97262\n",
      "[313]\ttrain-rmse:2863.03480\teval-rmse:2863.03480\n",
      "[314]\ttrain-rmse:2846.88390\teval-rmse:2846.88390\n",
      "[315]\ttrain-rmse:2832.83571\teval-rmse:2832.83571\n",
      "[316]\ttrain-rmse:2818.62337\teval-rmse:2818.62337\n",
      "[317]\ttrain-rmse:2803.48597\teval-rmse:2803.48597\n",
      "[318]\ttrain-rmse:2790.57653\teval-rmse:2790.57653\n",
      "[319]\ttrain-rmse:2775.48478\teval-rmse:2775.48478\n",
      "[320]\ttrain-rmse:2761.79636\teval-rmse:2761.79636\n",
      "[321]\ttrain-rmse:2747.12816\teval-rmse:2747.12816\n",
      "[322]\ttrain-rmse:2733.27448\teval-rmse:2733.27448\n",
      "[323]\ttrain-rmse:2720.22094\teval-rmse:2720.22094\n",
      "[324]\ttrain-rmse:2705.83517\teval-rmse:2705.83517\n",
      "[325]\ttrain-rmse:2690.19710\teval-rmse:2690.19710\n",
      "[326]\ttrain-rmse:2676.09608\teval-rmse:2676.09608\n",
      "[327]\ttrain-rmse:2662.37751\teval-rmse:2662.37751\n",
      "[328]\ttrain-rmse:2651.23297\teval-rmse:2651.23297\n",
      "[329]\ttrain-rmse:2637.67950\teval-rmse:2637.67950\n",
      "[330]\ttrain-rmse:2624.75414\teval-rmse:2624.75414\n",
      "[331]\ttrain-rmse:2612.24279\teval-rmse:2612.24279\n",
      "[332]\ttrain-rmse:2599.88723\teval-rmse:2599.88723\n",
      "[333]\ttrain-rmse:2586.21509\teval-rmse:2586.21509\n",
      "[334]\ttrain-rmse:2574.94219\teval-rmse:2574.94219\n",
      "[335]\ttrain-rmse:2560.90344\teval-rmse:2560.90344\n",
      "[336]\ttrain-rmse:2547.86618\teval-rmse:2547.86618\n",
      "[337]\ttrain-rmse:2537.22252\teval-rmse:2537.22252\n",
      "[338]\ttrain-rmse:2524.99496\teval-rmse:2524.99496\n",
      "[339]\ttrain-rmse:2512.28595\teval-rmse:2512.28595\n",
      "[340]\ttrain-rmse:2500.48685\teval-rmse:2500.48685\n",
      "[341]\ttrain-rmse:2488.05594\teval-rmse:2488.05594\n",
      "[342]\ttrain-rmse:2475.22150\teval-rmse:2475.22150\n",
      "[343]\ttrain-rmse:2462.11467\teval-rmse:2462.11467\n",
      "[344]\ttrain-rmse:2451.60065\teval-rmse:2451.60065\n",
      "[345]\ttrain-rmse:2439.64577\teval-rmse:2439.64577\n",
      "[346]\ttrain-rmse:2428.22574\teval-rmse:2428.22574\n",
      "[347]\ttrain-rmse:2415.91855\teval-rmse:2415.91855\n",
      "[348]\ttrain-rmse:2404.28926\teval-rmse:2404.28926\n",
      "[349]\ttrain-rmse:2391.81995\teval-rmse:2391.81995\n",
      "[350]\ttrain-rmse:2378.65007\teval-rmse:2378.65007\n",
      "[351]\ttrain-rmse:2366.07603\teval-rmse:2366.07603\n",
      "[352]\ttrain-rmse:2353.22277\teval-rmse:2353.22277\n",
      "[353]\ttrain-rmse:2341.57913\teval-rmse:2341.57913\n",
      "[354]\ttrain-rmse:2330.69717\teval-rmse:2330.69717\n",
      "[355]\ttrain-rmse:2318.42630\teval-rmse:2318.42630\n",
      "[356]\ttrain-rmse:2304.85074\teval-rmse:2304.85074\n",
      "[357]\ttrain-rmse:2293.70211\teval-rmse:2293.70211\n",
      "[358]\ttrain-rmse:2280.94261\teval-rmse:2280.94261\n",
      "[359]\ttrain-rmse:2270.24207\teval-rmse:2270.24207\n",
      "[360]\ttrain-rmse:2257.70322\teval-rmse:2257.70322\n",
      "[361]\ttrain-rmse:2245.85072\teval-rmse:2245.85072\n",
      "[362]\ttrain-rmse:2234.99807\teval-rmse:2234.99807\n",
      "[363]\ttrain-rmse:2223.88482\teval-rmse:2223.88482\n",
      "[364]\ttrain-rmse:2212.71326\teval-rmse:2212.71326\n",
      "[365]\ttrain-rmse:2201.88345\teval-rmse:2201.88345\n",
      "[366]\ttrain-rmse:2191.21632\teval-rmse:2191.21632\n",
      "[367]\ttrain-rmse:2180.95065\teval-rmse:2180.95065\n",
      "[368]\ttrain-rmse:2168.93639\teval-rmse:2168.93639\n",
      "[369]\ttrain-rmse:2157.43861\teval-rmse:2157.43861\n",
      "[370]\ttrain-rmse:2145.76101\teval-rmse:2145.76101\n",
      "[371]\ttrain-rmse:2134.54692\teval-rmse:2134.54692\n",
      "[372]\ttrain-rmse:2124.12528\teval-rmse:2124.12528\n",
      "[373]\ttrain-rmse:2112.63214\teval-rmse:2112.63214\n",
      "[374]\ttrain-rmse:2102.33812\teval-rmse:2102.33812\n",
      "[375]\ttrain-rmse:2092.64388\teval-rmse:2092.64388\n",
      "[376]\ttrain-rmse:2081.67425\teval-rmse:2081.67425\n",
      "[377]\ttrain-rmse:2072.06639\teval-rmse:2072.06639\n",
      "[378]\ttrain-rmse:2062.19247\teval-rmse:2062.19247\n",
      "[379]\ttrain-rmse:2051.82690\teval-rmse:2051.82690\n",
      "[380]\ttrain-rmse:2041.12567\teval-rmse:2041.12567\n",
      "[381]\ttrain-rmse:2031.96570\teval-rmse:2031.96570\n",
      "[382]\ttrain-rmse:2022.20427\teval-rmse:2022.20427\n",
      "[383]\ttrain-rmse:2012.51705\teval-rmse:2012.51705\n",
      "[384]\ttrain-rmse:2002.22525\teval-rmse:2002.22525\n",
      "[385]\ttrain-rmse:1991.07162\teval-rmse:1991.07162\n",
      "[386]\ttrain-rmse:1980.30047\teval-rmse:1980.30047\n",
      "[387]\ttrain-rmse:1970.46709\teval-rmse:1970.46709\n",
      "[388]\ttrain-rmse:1961.31429\teval-rmse:1961.31429\n",
      "[389]\ttrain-rmse:1950.82802\teval-rmse:1950.82802\n",
      "[390]\ttrain-rmse:1941.71255\teval-rmse:1941.71255\n",
      "[391]\ttrain-rmse:1932.45531\teval-rmse:1932.45531\n",
      "[392]\ttrain-rmse:1921.61303\teval-rmse:1921.61303\n",
      "[393]\ttrain-rmse:1911.90333\teval-rmse:1911.90333\n",
      "[394]\ttrain-rmse:1902.51071\teval-rmse:1902.51071\n",
      "[395]\ttrain-rmse:1892.04945\teval-rmse:1892.04945\n",
      "[396]\ttrain-rmse:1881.91250\teval-rmse:1881.91250\n",
      "[397]\ttrain-rmse:1872.31898\teval-rmse:1872.31898\n",
      "[398]\ttrain-rmse:1862.37827\teval-rmse:1862.37827\n",
      "[399]\ttrain-rmse:1854.59148\teval-rmse:1854.59148\n",
      "[400]\ttrain-rmse:1845.56399\teval-rmse:1845.56399\n",
      "[401]\ttrain-rmse:1836.30295\teval-rmse:1836.30295\n",
      "[402]\ttrain-rmse:1827.99047\teval-rmse:1827.99047\n",
      "[403]\ttrain-rmse:1819.32033\teval-rmse:1819.32033\n",
      "[404]\ttrain-rmse:1811.33577\teval-rmse:1811.33577\n",
      "[405]\ttrain-rmse:1801.87773\teval-rmse:1801.87773\n",
      "[406]\ttrain-rmse:1793.67363\teval-rmse:1793.67363\n",
      "[407]\ttrain-rmse:1783.10094\teval-rmse:1783.10094\n",
      "[408]\ttrain-rmse:1775.01001\teval-rmse:1775.01001\n",
      "[409]\ttrain-rmse:1766.34605\teval-rmse:1766.34605\n",
      "[410]\ttrain-rmse:1758.25684\teval-rmse:1758.25684\n",
      "[411]\ttrain-rmse:1748.76422\teval-rmse:1748.76422\n",
      "[412]\ttrain-rmse:1740.88668\teval-rmse:1740.88668\n",
      "[413]\ttrain-rmse:1732.46488\teval-rmse:1732.46488\n",
      "[414]\ttrain-rmse:1723.53937\teval-rmse:1723.53937\n",
      "[415]\ttrain-rmse:1714.23133\teval-rmse:1714.23133\n",
      "[416]\ttrain-rmse:1705.95267\teval-rmse:1705.95267\n",
      "[417]\ttrain-rmse:1697.57202\teval-rmse:1697.57202\n",
      "[418]\ttrain-rmse:1688.98650\teval-rmse:1688.98650\n",
      "[419]\ttrain-rmse:1680.08151\teval-rmse:1680.08151\n",
      "[420]\ttrain-rmse:1672.76319\teval-rmse:1672.76319\n",
      "[421]\ttrain-rmse:1663.79629\teval-rmse:1663.79629\n",
      "[422]\ttrain-rmse:1655.06193\teval-rmse:1655.06193\n",
      "[423]\ttrain-rmse:1646.26818\teval-rmse:1646.26818\n",
      "[424]\ttrain-rmse:1638.74411\teval-rmse:1638.74411\n",
      "[425]\ttrain-rmse:1630.08065\teval-rmse:1630.08065\n",
      "[426]\ttrain-rmse:1622.00749\teval-rmse:1622.00749\n",
      "[427]\ttrain-rmse:1613.47511\teval-rmse:1613.47511\n",
      "[428]\ttrain-rmse:1606.58048\teval-rmse:1606.58048\n",
      "[429]\ttrain-rmse:1597.89274\teval-rmse:1597.89274\n",
      "[430]\ttrain-rmse:1589.28289\teval-rmse:1589.28289\n",
      "[431]\ttrain-rmse:1581.38138\teval-rmse:1581.38138\n",
      "[432]\ttrain-rmse:1573.92629\teval-rmse:1573.92629\n",
      "[433]\ttrain-rmse:1566.24385\teval-rmse:1566.24385\n",
      "[434]\ttrain-rmse:1557.43401\teval-rmse:1557.43401\n",
      "[435]\ttrain-rmse:1550.61876\teval-rmse:1550.61876\n",
      "[436]\ttrain-rmse:1543.09202\teval-rmse:1543.09202\n",
      "[437]\ttrain-rmse:1535.97623\teval-rmse:1535.97623\n",
      "[438]\ttrain-rmse:1528.18298\teval-rmse:1528.18298\n",
      "[439]\ttrain-rmse:1521.20908\teval-rmse:1521.20908\n",
      "[440]\ttrain-rmse:1513.64977\teval-rmse:1513.64977\n",
      "[441]\ttrain-rmse:1506.60934\teval-rmse:1506.60934\n",
      "[442]\ttrain-rmse:1499.13146\teval-rmse:1499.13146\n",
      "[443]\ttrain-rmse:1493.02695\teval-rmse:1493.02695\n",
      "[444]\ttrain-rmse:1486.20786\teval-rmse:1486.20786\n",
      "[445]\ttrain-rmse:1478.29879\teval-rmse:1478.29879\n",
      "[446]\ttrain-rmse:1472.05135\teval-rmse:1472.05135\n",
      "[447]\ttrain-rmse:1464.57562\teval-rmse:1464.57562\n",
      "[448]\ttrain-rmse:1456.81473\teval-rmse:1456.81473\n",
      "[449]\ttrain-rmse:1449.55043\teval-rmse:1449.55043\n",
      "[450]\ttrain-rmse:1443.61536\teval-rmse:1443.61536\n",
      "[451]\ttrain-rmse:1435.83915\teval-rmse:1435.83915\n",
      "[452]\ttrain-rmse:1429.73997\teval-rmse:1429.73997\n",
      "[453]\ttrain-rmse:1423.20575\teval-rmse:1423.20575\n",
      "[454]\ttrain-rmse:1415.01436\teval-rmse:1415.01436\n",
      "[455]\ttrain-rmse:1408.97699\teval-rmse:1408.97699\n",
      "[456]\ttrain-rmse:1402.03641\teval-rmse:1402.03641\n",
      "[457]\ttrain-rmse:1396.12256\teval-rmse:1396.12256\n",
      "[458]\ttrain-rmse:1389.19560\teval-rmse:1389.19560\n",
      "[459]\ttrain-rmse:1382.35814\teval-rmse:1382.35814\n",
      "[460]\ttrain-rmse:1375.86307\teval-rmse:1375.86307\n",
      "[461]\ttrain-rmse:1368.70903\teval-rmse:1368.70903\n",
      "[462]\ttrain-rmse:1362.66593\teval-rmse:1362.66593\n",
      "[463]\ttrain-rmse:1356.34388\teval-rmse:1356.34388\n",
      "[464]\ttrain-rmse:1349.16028\teval-rmse:1349.16028\n",
      "[465]\ttrain-rmse:1342.36516\teval-rmse:1342.36516\n",
      "[466]\ttrain-rmse:1336.34303\teval-rmse:1336.34303\n",
      "[467]\ttrain-rmse:1329.43589\teval-rmse:1329.43589\n",
      "[468]\ttrain-rmse:1323.88560\teval-rmse:1323.88560\n",
      "[469]\ttrain-rmse:1316.96162\teval-rmse:1316.96162\n",
      "[470]\ttrain-rmse:1311.23716\teval-rmse:1311.23716\n",
      "[471]\ttrain-rmse:1304.45354\teval-rmse:1304.45354\n",
      "[472]\ttrain-rmse:1298.61940\teval-rmse:1298.61940\n",
      "[473]\ttrain-rmse:1292.85771\teval-rmse:1292.85771\n",
      "[474]\ttrain-rmse:1287.13442\teval-rmse:1287.13442\n",
      "[475]\ttrain-rmse:1280.97713\teval-rmse:1280.97713\n",
      "[476]\ttrain-rmse:1273.85810\teval-rmse:1273.85810\n",
      "[477]\ttrain-rmse:1267.74692\teval-rmse:1267.74692\n",
      "[478]\ttrain-rmse:1261.88906\teval-rmse:1261.88906\n",
      "[479]\ttrain-rmse:1255.06854\teval-rmse:1255.06854\n",
      "[480]\ttrain-rmse:1250.50546\teval-rmse:1250.50546\n",
      "[481]\ttrain-rmse:1245.11597\teval-rmse:1245.11597\n",
      "[482]\ttrain-rmse:1238.90871\teval-rmse:1238.90871\n",
      "[483]\ttrain-rmse:1232.11470\teval-rmse:1232.11470\n",
      "[484]\ttrain-rmse:1225.96443\teval-rmse:1225.96443\n",
      "[485]\ttrain-rmse:1219.36661\teval-rmse:1219.36661\n",
      "[486]\ttrain-rmse:1213.87662\teval-rmse:1213.87662\n",
      "[487]\ttrain-rmse:1208.73921\teval-rmse:1208.73921\n",
      "[488]\ttrain-rmse:1202.78708\teval-rmse:1202.78708\n",
      "[489]\ttrain-rmse:1196.89624\teval-rmse:1196.89624\n",
      "[490]\ttrain-rmse:1191.07887\teval-rmse:1191.07887\n",
      "[491]\ttrain-rmse:1185.99099\teval-rmse:1185.99099\n",
      "[492]\ttrain-rmse:1179.98057\teval-rmse:1179.98057\n",
      "[493]\ttrain-rmse:1174.14431\teval-rmse:1174.14431\n",
      "[494]\ttrain-rmse:1168.35114\teval-rmse:1168.35114\n",
      "[495]\ttrain-rmse:1162.43292\teval-rmse:1162.43292\n",
      "[496]\ttrain-rmse:1157.31393\teval-rmse:1157.31393\n",
      "[497]\ttrain-rmse:1151.74964\teval-rmse:1151.74964\n",
      "[498]\ttrain-rmse:1146.94195\teval-rmse:1146.94195\n",
      "[499]\ttrain-rmse:1141.96776\teval-rmse:1141.96776\n",
      "[500]\ttrain-rmse:1136.48923\teval-rmse:1136.48923\n",
      "[501]\ttrain-rmse:1131.22321\teval-rmse:1131.22321\n",
      "[502]\ttrain-rmse:1125.47071\teval-rmse:1125.47071\n",
      "[503]\ttrain-rmse:1120.13258\teval-rmse:1120.13258\n",
      "[504]\ttrain-rmse:1114.52030\teval-rmse:1114.52030\n",
      "[505]\ttrain-rmse:1109.25722\teval-rmse:1109.25722\n",
      "[506]\ttrain-rmse:1104.42109\teval-rmse:1104.42109\n",
      "[507]\ttrain-rmse:1099.33828\teval-rmse:1099.33828\n",
      "[508]\ttrain-rmse:1094.09699\teval-rmse:1094.09699\n",
      "[509]\ttrain-rmse:1089.26089\teval-rmse:1089.26089\n",
      "[510]\ttrain-rmse:1084.31721\teval-rmse:1084.31721\n",
      "[511]\ttrain-rmse:1079.20335\teval-rmse:1079.20335\n",
      "[512]\ttrain-rmse:1075.21956\teval-rmse:1075.21956\n",
      "[513]\ttrain-rmse:1070.18747\teval-rmse:1070.18747\n",
      "[514]\ttrain-rmse:1065.50507\teval-rmse:1065.50507\n",
      "[515]\ttrain-rmse:1059.57257\teval-rmse:1059.57257\n",
      "[516]\ttrain-rmse:1054.75853\teval-rmse:1054.75853\n",
      "[517]\ttrain-rmse:1050.00653\teval-rmse:1050.00653\n",
      "[518]\ttrain-rmse:1045.33745\teval-rmse:1045.33745\n",
      "[519]\ttrain-rmse:1040.25142\teval-rmse:1040.25142\n",
      "[520]\ttrain-rmse:1036.36080\teval-rmse:1036.36080\n",
      "[521]\ttrain-rmse:1031.56174\teval-rmse:1031.56174\n",
      "[522]\ttrain-rmse:1027.13453\teval-rmse:1027.13453\n",
      "[523]\ttrain-rmse:1022.20568\teval-rmse:1022.20568\n",
      "[524]\ttrain-rmse:1017.60729\teval-rmse:1017.60729\n",
      "[525]\ttrain-rmse:1013.25452\teval-rmse:1013.25452\n",
      "[526]\ttrain-rmse:1008.63842\teval-rmse:1008.63842\n",
      "[527]\ttrain-rmse:1004.61017\teval-rmse:1004.61017\n",
      "[528]\ttrain-rmse:1000.61318\teval-rmse:1000.61318\n",
      "[529]\ttrain-rmse:995.92746\teval-rmse:995.92746\n",
      "[530]\ttrain-rmse:991.58358\teval-rmse:991.58358\n",
      "[531]\ttrain-rmse:987.01897\teval-rmse:987.01897\n",
      "[532]\ttrain-rmse:982.19779\teval-rmse:982.19779\n",
      "[533]\ttrain-rmse:977.20237\teval-rmse:977.20237\n",
      "[534]\ttrain-rmse:972.79133\teval-rmse:972.79133\n",
      "[535]\ttrain-rmse:968.21895\teval-rmse:968.21895\n",
      "[536]\ttrain-rmse:963.83078\teval-rmse:963.83078\n",
      "[537]\ttrain-rmse:959.26850\teval-rmse:959.26850\n",
      "[538]\ttrain-rmse:955.47108\teval-rmse:955.47108\n",
      "[539]\ttrain-rmse:951.43593\teval-rmse:951.43593\n",
      "[540]\ttrain-rmse:946.80686\teval-rmse:946.80686\n",
      "[541]\ttrain-rmse:942.34716\teval-rmse:942.34716\n",
      "[542]\ttrain-rmse:937.69788\teval-rmse:937.69788\n",
      "[543]\ttrain-rmse:933.38818\teval-rmse:933.38818\n",
      "[544]\ttrain-rmse:928.90373\teval-rmse:928.90373\n",
      "[545]\ttrain-rmse:924.35547\teval-rmse:924.35547\n",
      "[546]\ttrain-rmse:919.36957\teval-rmse:919.36957\n",
      "[547]\ttrain-rmse:915.43418\teval-rmse:915.43418\n",
      "[548]\ttrain-rmse:910.35874\teval-rmse:910.35874\n",
      "[549]\ttrain-rmse:906.20092\teval-rmse:906.20092\n",
      "[550]\ttrain-rmse:901.98882\teval-rmse:901.98882\n",
      "[551]\ttrain-rmse:898.31352\teval-rmse:898.31352\n",
      "[552]\ttrain-rmse:894.85293\teval-rmse:894.85293\n",
      "[553]\ttrain-rmse:891.43565\teval-rmse:891.43565\n",
      "[554]\ttrain-rmse:887.39579\teval-rmse:887.39579\n",
      "[555]\ttrain-rmse:882.99956\teval-rmse:882.99956\n",
      "[556]\ttrain-rmse:878.87792\teval-rmse:878.87792\n",
      "[557]\ttrain-rmse:875.06513\teval-rmse:875.06513\n",
      "[558]\ttrain-rmse:870.39380\teval-rmse:870.39380\n",
      "[559]\ttrain-rmse:866.32781\teval-rmse:866.32781\n",
      "[560]\ttrain-rmse:862.94103\teval-rmse:862.94103\n",
      "[561]\ttrain-rmse:858.93191\teval-rmse:858.93191\n",
      "[562]\ttrain-rmse:854.86311\teval-rmse:854.86311\n",
      "[563]\ttrain-rmse:851.62124\teval-rmse:851.62124\n",
      "[564]\ttrain-rmse:847.58421\teval-rmse:847.58421\n",
      "[565]\ttrain-rmse:844.24921\teval-rmse:844.24921\n",
      "[566]\ttrain-rmse:840.20455\teval-rmse:840.20455\n",
      "[567]\ttrain-rmse:836.30816\teval-rmse:836.30816\n",
      "[568]\ttrain-rmse:832.93648\teval-rmse:832.93648\n",
      "[569]\ttrain-rmse:829.54803\teval-rmse:829.54803\n",
      "[570]\ttrain-rmse:825.63844\teval-rmse:825.63844\n",
      "[571]\ttrain-rmse:821.47689\teval-rmse:821.47689\n",
      "[572]\ttrain-rmse:817.46944\teval-rmse:817.46944\n",
      "[573]\ttrain-rmse:814.04907\teval-rmse:814.04907\n",
      "[574]\ttrain-rmse:810.52420\teval-rmse:810.52420\n",
      "[575]\ttrain-rmse:806.86231\teval-rmse:806.86231\n",
      "[576]\ttrain-rmse:803.08738\teval-rmse:803.08738\n",
      "[577]\ttrain-rmse:799.79870\teval-rmse:799.79870\n",
      "[578]\ttrain-rmse:796.17415\teval-rmse:796.17415\n",
      "[579]\ttrain-rmse:792.54017\teval-rmse:792.54017\n",
      "[580]\ttrain-rmse:788.90352\teval-rmse:788.90352\n",
      "[581]\ttrain-rmse:785.39272\teval-rmse:785.39272\n",
      "[582]\ttrain-rmse:781.11162\teval-rmse:781.11162\n",
      "[583]\ttrain-rmse:778.14809\teval-rmse:778.14809\n",
      "[584]\ttrain-rmse:774.76361\teval-rmse:774.76361\n",
      "[585]\ttrain-rmse:771.38927\teval-rmse:771.38927\n",
      "[586]\ttrain-rmse:767.56407\teval-rmse:767.56407\n",
      "[587]\ttrain-rmse:764.62362\teval-rmse:764.62362\n",
      "[588]\ttrain-rmse:761.51104\teval-rmse:761.51104\n",
      "[589]\ttrain-rmse:758.36912\teval-rmse:758.36912\n",
      "[590]\ttrain-rmse:754.62681\teval-rmse:754.62681\n",
      "[591]\ttrain-rmse:751.02259\teval-rmse:751.02259\n",
      "[592]\ttrain-rmse:747.54113\teval-rmse:747.54113\n",
      "[593]\ttrain-rmse:744.08142\teval-rmse:744.08142\n",
      "[594]\ttrain-rmse:740.81717\teval-rmse:740.81717\n",
      "[595]\ttrain-rmse:737.57384\teval-rmse:737.57384\n",
      "[596]\ttrain-rmse:734.15621\teval-rmse:734.15621\n",
      "[597]\ttrain-rmse:730.79469\teval-rmse:730.79469\n",
      "[598]\ttrain-rmse:727.04472\teval-rmse:727.04472\n",
      "[599]\ttrain-rmse:723.75871\teval-rmse:723.75871\n",
      "[600]\ttrain-rmse:720.54739\teval-rmse:720.54739\n",
      "[601]\ttrain-rmse:717.21752\teval-rmse:717.21752\n",
      "[602]\ttrain-rmse:714.20180\teval-rmse:714.20180\n",
      "[603]\ttrain-rmse:711.30033\teval-rmse:711.30033\n",
      "[604]\ttrain-rmse:708.55463\teval-rmse:708.55463\n",
      "[605]\ttrain-rmse:705.26424\teval-rmse:705.26424\n",
      "[606]\ttrain-rmse:701.83122\teval-rmse:701.83122\n",
      "[607]\ttrain-rmse:698.46770\teval-rmse:698.46770\n",
      "[608]\ttrain-rmse:695.15630\teval-rmse:695.15630\n",
      "[609]\ttrain-rmse:692.66000\teval-rmse:692.66000\n",
      "[610]\ttrain-rmse:690.04362\teval-rmse:690.04362\n",
      "[611]\ttrain-rmse:687.41851\teval-rmse:687.41851\n",
      "[612]\ttrain-rmse:684.35256\teval-rmse:684.35256\n",
      "[613]\ttrain-rmse:681.39438\teval-rmse:681.39438\n",
      "[614]\ttrain-rmse:678.64998\teval-rmse:678.64998\n",
      "[615]\ttrain-rmse:675.61323\teval-rmse:675.61323\n",
      "[616]\ttrain-rmse:672.82543\teval-rmse:672.82543\n",
      "[617]\ttrain-rmse:669.80761\teval-rmse:669.80761\n",
      "[618]\ttrain-rmse:667.04076\teval-rmse:667.04076\n",
      "[619]\ttrain-rmse:664.45926\teval-rmse:664.45926\n",
      "[620]\ttrain-rmse:661.75517\teval-rmse:661.75517\n",
      "[621]\ttrain-rmse:658.65980\teval-rmse:658.65980\n",
      "[622]\ttrain-rmse:655.41088\teval-rmse:655.41088\n",
      "[623]\ttrain-rmse:652.71003\teval-rmse:652.71003\n",
      "[624]\ttrain-rmse:650.06141\teval-rmse:650.06141\n",
      "[625]\ttrain-rmse:647.27535\teval-rmse:647.27535\n",
      "[626]\ttrain-rmse:644.64438\teval-rmse:644.64438\n",
      "[627]\ttrain-rmse:641.36079\teval-rmse:641.36079\n",
      "[628]\ttrain-rmse:638.06882\teval-rmse:638.06882\n",
      "[629]\ttrain-rmse:635.33320\teval-rmse:635.33320\n",
      "[630]\ttrain-rmse:632.65323\teval-rmse:632.65323\n",
      "[631]\ttrain-rmse:629.79312\teval-rmse:629.79312\n",
      "[632]\ttrain-rmse:627.00766\teval-rmse:627.00766\n",
      "[633]\ttrain-rmse:624.12356\teval-rmse:624.12356\n",
      "[634]\ttrain-rmse:621.51810\teval-rmse:621.51810\n",
      "[635]\ttrain-rmse:619.06746\teval-rmse:619.06746\n",
      "[636]\ttrain-rmse:616.06846\teval-rmse:616.06846\n",
      "[637]\ttrain-rmse:613.10716\teval-rmse:613.10716\n",
      "[638]\ttrain-rmse:610.48645\teval-rmse:610.48645\n",
      "[639]\ttrain-rmse:607.83660\teval-rmse:607.83660\n",
      "[640]\ttrain-rmse:605.66957\teval-rmse:605.66957\n",
      "[641]\ttrain-rmse:603.03486\teval-rmse:603.03486\n",
      "[642]\ttrain-rmse:600.33409\teval-rmse:600.33409\n",
      "[643]\ttrain-rmse:597.56535\teval-rmse:597.56535\n",
      "[644]\ttrain-rmse:595.05643\teval-rmse:595.05643\n",
      "[645]\ttrain-rmse:592.55712\teval-rmse:592.55712\n",
      "[646]\ttrain-rmse:589.94707\teval-rmse:589.94707\n",
      "[647]\ttrain-rmse:587.45452\teval-rmse:587.45452\n",
      "[648]\ttrain-rmse:584.94067\teval-rmse:584.94067\n",
      "[649]\ttrain-rmse:582.19498\teval-rmse:582.19498\n",
      "[650]\ttrain-rmse:579.69447\teval-rmse:579.69447\n",
      "[651]\ttrain-rmse:577.09123\teval-rmse:577.09123\n",
      "[652]\ttrain-rmse:574.59698\teval-rmse:574.59698\n",
      "[653]\ttrain-rmse:572.16904\teval-rmse:572.16904\n",
      "[654]\ttrain-rmse:569.39808\teval-rmse:569.39808\n",
      "[655]\ttrain-rmse:566.94464\teval-rmse:566.94464\n",
      "[656]\ttrain-rmse:564.69906\teval-rmse:564.69906\n",
      "[657]\ttrain-rmse:562.41658\teval-rmse:562.41658\n",
      "[658]\ttrain-rmse:560.06505\teval-rmse:560.06505\n",
      "[659]\ttrain-rmse:557.97875\teval-rmse:557.97875\n",
      "[660]\ttrain-rmse:555.87297\teval-rmse:555.87297\n",
      "[661]\ttrain-rmse:553.39506\teval-rmse:553.39506\n",
      "[662]\ttrain-rmse:551.27759\teval-rmse:551.27759\n",
      "[663]\ttrain-rmse:549.02759\teval-rmse:549.02759\n",
      "[664]\ttrain-rmse:546.80811\teval-rmse:546.80811\n",
      "[665]\ttrain-rmse:544.60838\teval-rmse:544.60838\n",
      "[666]\ttrain-rmse:542.40992\teval-rmse:542.40992\n",
      "[667]\ttrain-rmse:539.95030\teval-rmse:539.95030\n",
      "[668]\ttrain-rmse:537.88910\teval-rmse:537.88910\n",
      "[669]\ttrain-rmse:535.59653\teval-rmse:535.59653\n",
      "[670]\ttrain-rmse:533.36640\teval-rmse:533.36640\n",
      "[671]\ttrain-rmse:531.07365\teval-rmse:531.07365\n",
      "[672]\ttrain-rmse:529.02203\teval-rmse:529.02203\n",
      "[673]\ttrain-rmse:526.81238\teval-rmse:526.81238\n",
      "[674]\ttrain-rmse:524.87418\teval-rmse:524.87418\n",
      "[675]\ttrain-rmse:522.67401\teval-rmse:522.67401\n",
      "[676]\ttrain-rmse:520.30323\teval-rmse:520.30323\n",
      "[677]\ttrain-rmse:518.50050\teval-rmse:518.50050\n",
      "[678]\ttrain-rmse:516.40650\teval-rmse:516.40650\n",
      "[679]\ttrain-rmse:514.30356\teval-rmse:514.30356\n",
      "[680]\ttrain-rmse:512.28811\teval-rmse:512.28811\n",
      "[681]\ttrain-rmse:509.94910\teval-rmse:509.94910\n",
      "[682]\ttrain-rmse:507.62993\teval-rmse:507.62993\n",
      "[683]\ttrain-rmse:505.67243\teval-rmse:505.67243\n",
      "[684]\ttrain-rmse:503.38157\teval-rmse:503.38157\n",
      "[685]\ttrain-rmse:501.22966\teval-rmse:501.22966\n",
      "[686]\ttrain-rmse:499.19513\teval-rmse:499.19513\n",
      "[687]\ttrain-rmse:496.92341\teval-rmse:496.92341\n",
      "[688]\ttrain-rmse:495.07426\teval-rmse:495.07426\n",
      "[689]\ttrain-rmse:493.27119\teval-rmse:493.27119\n",
      "[690]\ttrain-rmse:491.18369\teval-rmse:491.18369\n",
      "[691]\ttrain-rmse:489.10866\teval-rmse:489.10866\n",
      "[692]\ttrain-rmse:487.36249\teval-rmse:487.36249\n",
      "[693]\ttrain-rmse:485.38210\teval-rmse:485.38210\n",
      "[694]\ttrain-rmse:483.54611\teval-rmse:483.54611\n",
      "[695]\ttrain-rmse:481.36085\teval-rmse:481.36085\n",
      "[696]\ttrain-rmse:479.29423\teval-rmse:479.29423\n",
      "[697]\ttrain-rmse:477.21378\teval-rmse:477.21378\n",
      "[698]\ttrain-rmse:475.59307\teval-rmse:475.59307\n",
      "[699]\ttrain-rmse:473.67266\teval-rmse:473.67266\n",
      "[700]\ttrain-rmse:471.62445\teval-rmse:471.62445\n",
      "[701]\ttrain-rmse:469.61036\teval-rmse:469.61036\n",
      "[702]\ttrain-rmse:467.71212\teval-rmse:467.71212\n",
      "[703]\ttrain-rmse:465.85061\teval-rmse:465.85061\n",
      "[704]\ttrain-rmse:464.08892\teval-rmse:464.08892\n",
      "[705]\ttrain-rmse:462.56289\teval-rmse:462.56289\n",
      "[706]\ttrain-rmse:460.71004\teval-rmse:460.71004\n",
      "[707]\ttrain-rmse:458.80346\teval-rmse:458.80346\n",
      "[708]\ttrain-rmse:456.99018\teval-rmse:456.99018\n",
      "[709]\ttrain-rmse:455.48433\teval-rmse:455.48433\n",
      "[710]\ttrain-rmse:453.39509\teval-rmse:453.39509\n",
      "[711]\ttrain-rmse:451.52758\teval-rmse:451.52758\n",
      "[712]\ttrain-rmse:449.55994\teval-rmse:449.55994\n",
      "[713]\ttrain-rmse:447.89508\teval-rmse:447.89508\n",
      "[714]\ttrain-rmse:446.21374\teval-rmse:446.21374\n",
      "[715]\ttrain-rmse:444.42537\teval-rmse:444.42537\n",
      "[716]\ttrain-rmse:442.52292\teval-rmse:442.52292\n",
      "[717]\ttrain-rmse:440.53448\teval-rmse:440.53448\n",
      "[718]\ttrain-rmse:438.65456\teval-rmse:438.65456\n",
      "[719]\ttrain-rmse:436.88771\teval-rmse:436.88771\n",
      "[720]\ttrain-rmse:435.18570\teval-rmse:435.18570\n",
      "[721]\ttrain-rmse:433.52339\teval-rmse:433.52339\n",
      "[722]\ttrain-rmse:431.85304\teval-rmse:431.85304\n",
      "[723]\ttrain-rmse:430.46117\teval-rmse:430.46117\n",
      "[724]\ttrain-rmse:428.86469\teval-rmse:428.86469\n",
      "[725]\ttrain-rmse:427.18902\teval-rmse:427.18902\n",
      "[726]\ttrain-rmse:425.57090\teval-rmse:425.57090\n",
      "[727]\ttrain-rmse:423.87882\teval-rmse:423.87882\n",
      "[728]\ttrain-rmse:422.20571\teval-rmse:422.20571\n",
      "[729]\ttrain-rmse:420.79298\teval-rmse:420.79298\n",
      "[730]\ttrain-rmse:419.04354\teval-rmse:419.04354\n",
      "[731]\ttrain-rmse:417.38199\teval-rmse:417.38199\n",
      "[732]\ttrain-rmse:415.81892\teval-rmse:415.81892\n",
      "[733]\ttrain-rmse:413.90016\teval-rmse:413.90016\n",
      "[734]\ttrain-rmse:411.99867\teval-rmse:411.99867\n",
      "[735]\ttrain-rmse:410.27703\teval-rmse:410.27703\n",
      "[736]\ttrain-rmse:408.66931\teval-rmse:408.66931\n",
      "[737]\ttrain-rmse:406.75854\teval-rmse:406.75854\n",
      "[738]\ttrain-rmse:405.54876\teval-rmse:405.54876\n",
      "[739]\ttrain-rmse:403.86754\teval-rmse:403.86754\n",
      "[740]\ttrain-rmse:402.45131\teval-rmse:402.45131\n",
      "[741]\ttrain-rmse:401.07550\teval-rmse:401.07550\n",
      "[742]\ttrain-rmse:399.23258\teval-rmse:399.23258\n",
      "[743]\ttrain-rmse:397.34756\teval-rmse:397.34756\n",
      "[744]\ttrain-rmse:395.71106\teval-rmse:395.71106\n",
      "[745]\ttrain-rmse:394.22358\teval-rmse:394.22358\n",
      "[746]\ttrain-rmse:392.88626\teval-rmse:392.88626\n",
      "[747]\ttrain-rmse:391.37022\teval-rmse:391.37022\n",
      "[748]\ttrain-rmse:389.84906\teval-rmse:389.84906\n",
      "[749]\ttrain-rmse:388.32947\teval-rmse:388.32947\n",
      "[750]\ttrain-rmse:386.89987\teval-rmse:386.89987\n",
      "[751]\ttrain-rmse:385.21364\teval-rmse:385.21364\n",
      "[752]\ttrain-rmse:383.60600\teval-rmse:383.60600\n",
      "[753]\ttrain-rmse:382.11006\teval-rmse:382.11006\n",
      "[754]\ttrain-rmse:380.69876\teval-rmse:380.69876\n",
      "[755]\ttrain-rmse:379.44492\teval-rmse:379.44492\n",
      "[756]\ttrain-rmse:377.86097\teval-rmse:377.86097\n",
      "[757]\ttrain-rmse:376.04132\teval-rmse:376.04132\n",
      "[758]\ttrain-rmse:374.60179\teval-rmse:374.60179\n",
      "[759]\ttrain-rmse:373.21561\teval-rmse:373.21561\n",
      "[760]\ttrain-rmse:371.63680\teval-rmse:371.63680\n",
      "[761]\ttrain-rmse:370.14077\teval-rmse:370.14077\n",
      "[762]\ttrain-rmse:368.67190\teval-rmse:368.67190\n",
      "[763]\ttrain-rmse:367.29434\teval-rmse:367.29434\n",
      "[764]\ttrain-rmse:365.92504\teval-rmse:365.92504\n",
      "[765]\ttrain-rmse:364.59127\teval-rmse:364.59127\n",
      "[766]\ttrain-rmse:363.25402\teval-rmse:363.25402\n",
      "[767]\ttrain-rmse:362.08202\teval-rmse:362.08202\n",
      "[768]\ttrain-rmse:360.57692\teval-rmse:360.57692\n",
      "[769]\ttrain-rmse:359.18460\teval-rmse:359.18460\n",
      "[770]\ttrain-rmse:357.81544\teval-rmse:357.81544\n",
      "[771]\ttrain-rmse:356.80646\teval-rmse:356.80646\n",
      "[772]\ttrain-rmse:355.76263\teval-rmse:355.76263\n",
      "[773]\ttrain-rmse:354.14077\teval-rmse:354.14077\n",
      "[774]\ttrain-rmse:353.01931\teval-rmse:353.01931\n",
      "[775]\ttrain-rmse:351.70344\teval-rmse:351.70344\n",
      "[776]\ttrain-rmse:350.33520\teval-rmse:350.33520\n",
      "[777]\ttrain-rmse:348.84292\teval-rmse:348.84292\n",
      "[778]\ttrain-rmse:347.77471\teval-rmse:347.77471\n",
      "[779]\ttrain-rmse:346.55423\teval-rmse:346.55423\n",
      "[780]\ttrain-rmse:345.17698\teval-rmse:345.17698\n",
      "[781]\ttrain-rmse:343.83580\teval-rmse:343.83580\n",
      "[782]\ttrain-rmse:342.34787\teval-rmse:342.34787\n",
      "[783]\ttrain-rmse:341.01097\teval-rmse:341.01097\n",
      "[784]\ttrain-rmse:339.63635\teval-rmse:339.63635\n",
      "[785]\ttrain-rmse:338.09541\teval-rmse:338.09541\n",
      "[786]\ttrain-rmse:336.94331\teval-rmse:336.94331\n",
      "[787]\ttrain-rmse:335.72969\teval-rmse:335.72969\n",
      "[788]\ttrain-rmse:334.32849\teval-rmse:334.32849\n",
      "[789]\ttrain-rmse:332.97971\teval-rmse:332.97971\n",
      "[790]\ttrain-rmse:331.79994\teval-rmse:331.79994\n",
      "[791]\ttrain-rmse:330.69930\teval-rmse:330.69930\n",
      "[792]\ttrain-rmse:329.61537\teval-rmse:329.61537\n",
      "[793]\ttrain-rmse:328.32553\teval-rmse:328.32553\n",
      "[794]\ttrain-rmse:326.97880\teval-rmse:326.97880\n",
      "[795]\ttrain-rmse:326.13925\teval-rmse:326.13925\n",
      "[796]\ttrain-rmse:325.06675\teval-rmse:325.06675\n",
      "[797]\ttrain-rmse:323.75996\teval-rmse:323.75996\n",
      "[798]\ttrain-rmse:322.57909\teval-rmse:322.57909\n",
      "[799]\ttrain-rmse:321.20375\teval-rmse:321.20375\n",
      "[800]\ttrain-rmse:320.07519\teval-rmse:320.07519\n",
      "[801]\ttrain-rmse:318.88507\teval-rmse:318.88507\n",
      "[802]\ttrain-rmse:317.67069\teval-rmse:317.67069\n",
      "[803]\ttrain-rmse:316.39524\teval-rmse:316.39524\n",
      "[804]\ttrain-rmse:315.17328\teval-rmse:315.17328\n",
      "[805]\ttrain-rmse:313.96893\teval-rmse:313.96893\n",
      "[806]\ttrain-rmse:312.76411\teval-rmse:312.76411\n",
      "[807]\ttrain-rmse:311.63219\teval-rmse:311.63219\n",
      "[808]\ttrain-rmse:310.46183\teval-rmse:310.46183\n",
      "[809]\ttrain-rmse:309.43775\teval-rmse:309.43775\n",
      "[810]\ttrain-rmse:308.30777\teval-rmse:308.30777\n",
      "[811]\ttrain-rmse:307.00439\teval-rmse:307.00439\n",
      "[812]\ttrain-rmse:305.91272\teval-rmse:305.91272\n",
      "[813]\ttrain-rmse:304.74034\teval-rmse:304.74034\n",
      "[814]\ttrain-rmse:303.64010\teval-rmse:303.64010\n",
      "[815]\ttrain-rmse:302.44368\teval-rmse:302.44368\n",
      "[816]\ttrain-rmse:301.30969\teval-rmse:301.30969\n",
      "[817]\ttrain-rmse:300.12295\teval-rmse:300.12295\n",
      "[818]\ttrain-rmse:299.09709\teval-rmse:299.09709\n",
      "[819]\ttrain-rmse:297.99236\teval-rmse:297.99236\n",
      "[820]\ttrain-rmse:296.93073\teval-rmse:296.93073\n",
      "[821]\ttrain-rmse:295.92403\teval-rmse:295.92403\n",
      "[822]\ttrain-rmse:295.01162\teval-rmse:295.01162\n",
      "[823]\ttrain-rmse:293.66825\teval-rmse:293.66825\n",
      "[824]\ttrain-rmse:292.61929\teval-rmse:292.61929\n",
      "[825]\ttrain-rmse:291.86625\teval-rmse:291.86625\n",
      "[826]\ttrain-rmse:290.76143\teval-rmse:290.76143\n",
      "[827]\ttrain-rmse:289.75461\teval-rmse:289.75461\n",
      "[828]\ttrain-rmse:288.74994\teval-rmse:288.74994\n",
      "[829]\ttrain-rmse:287.54359\teval-rmse:287.54359\n",
      "[830]\ttrain-rmse:286.50758\teval-rmse:286.50758\n",
      "[831]\ttrain-rmse:285.57351\teval-rmse:285.57351\n",
      "[832]\ttrain-rmse:284.52063\teval-rmse:284.52063\n",
      "[833]\ttrain-rmse:283.49475\teval-rmse:283.49475\n",
      "[834]\ttrain-rmse:282.54695\teval-rmse:282.54695\n",
      "[835]\ttrain-rmse:281.39179\teval-rmse:281.39179\n",
      "[836]\ttrain-rmse:280.55279\teval-rmse:280.55279\n",
      "[837]\ttrain-rmse:279.64846\teval-rmse:279.64846\n",
      "[838]\ttrain-rmse:278.58804\teval-rmse:278.58804\n",
      "[839]\ttrain-rmse:277.66647\teval-rmse:277.66647\n",
      "[840]\ttrain-rmse:276.57835\teval-rmse:276.57835\n",
      "[841]\ttrain-rmse:275.45439\teval-rmse:275.45439\n",
      "[842]\ttrain-rmse:274.61089\teval-rmse:274.61089\n",
      "[843]\ttrain-rmse:273.74338\teval-rmse:273.74338\n",
      "[844]\ttrain-rmse:272.73491\teval-rmse:272.73491\n",
      "[845]\ttrain-rmse:271.67906\teval-rmse:271.67906\n",
      "[846]\ttrain-rmse:270.81680\teval-rmse:270.81680\n",
      "[847]\ttrain-rmse:269.83724\teval-rmse:269.83724\n",
      "[848]\ttrain-rmse:268.99661\teval-rmse:268.99661\n",
      "[849]\ttrain-rmse:268.02397\teval-rmse:268.02397\n",
      "[850]\ttrain-rmse:267.01669\teval-rmse:267.01669\n",
      "[851]\ttrain-rmse:266.02487\teval-rmse:266.02487\n",
      "[852]\ttrain-rmse:265.19463\teval-rmse:265.19463\n",
      "[853]\ttrain-rmse:264.25725\teval-rmse:264.25725\n",
      "[854]\ttrain-rmse:263.39782\teval-rmse:263.39782\n",
      "[855]\ttrain-rmse:262.61676\teval-rmse:262.61676\n",
      "[856]\ttrain-rmse:261.69701\teval-rmse:261.69701\n",
      "[857]\ttrain-rmse:260.80178\teval-rmse:260.80178\n",
      "[858]\ttrain-rmse:259.98859\teval-rmse:259.98859\n",
      "[859]\ttrain-rmse:259.21427\teval-rmse:259.21427\n",
      "[860]\ttrain-rmse:258.23069\teval-rmse:258.23069\n",
      "[861]\ttrain-rmse:257.24482\teval-rmse:257.24482\n",
      "[862]\ttrain-rmse:256.43390\teval-rmse:256.43390\n",
      "[863]\ttrain-rmse:255.46177\teval-rmse:255.46177\n",
      "[864]\ttrain-rmse:254.57870\teval-rmse:254.57870\n",
      "[865]\ttrain-rmse:253.65546\teval-rmse:253.65546\n",
      "[866]\ttrain-rmse:252.79830\teval-rmse:252.79830\n",
      "[867]\ttrain-rmse:251.72032\teval-rmse:251.72032\n",
      "[868]\ttrain-rmse:250.87236\teval-rmse:250.87236\n",
      "[869]\ttrain-rmse:249.92223\teval-rmse:249.92223\n",
      "[870]\ttrain-rmse:249.28023\teval-rmse:249.28023\n",
      "[871]\ttrain-rmse:248.30181\teval-rmse:248.30181\n",
      "[872]\ttrain-rmse:247.53611\teval-rmse:247.53611\n",
      "[873]\ttrain-rmse:246.63115\teval-rmse:246.63115\n",
      "[874]\ttrain-rmse:245.82913\teval-rmse:245.82913\n",
      "[875]\ttrain-rmse:244.97350\teval-rmse:244.97350\n",
      "[876]\ttrain-rmse:244.04536\teval-rmse:244.04536\n",
      "[877]\ttrain-rmse:243.13533\teval-rmse:243.13533\n",
      "[878]\ttrain-rmse:242.16938\teval-rmse:242.16938\n",
      "[879]\ttrain-rmse:241.36137\teval-rmse:241.36137\n",
      "[880]\ttrain-rmse:240.55423\teval-rmse:240.55423\n",
      "[881]\ttrain-rmse:239.71017\teval-rmse:239.71017\n",
      "[882]\ttrain-rmse:238.89445\teval-rmse:238.89445\n",
      "[883]\ttrain-rmse:237.99989\teval-rmse:237.99989\n",
      "[884]\ttrain-rmse:237.16916\teval-rmse:237.16916\n",
      "[885]\ttrain-rmse:236.07676\teval-rmse:236.07676\n",
      "[886]\ttrain-rmse:235.18904\teval-rmse:235.18904\n",
      "[887]\ttrain-rmse:234.30306\teval-rmse:234.30306\n",
      "[888]\ttrain-rmse:233.44784\teval-rmse:233.44784\n",
      "[889]\ttrain-rmse:232.65335\teval-rmse:232.65335\n",
      "[890]\ttrain-rmse:231.80421\teval-rmse:231.80421\n",
      "[891]\ttrain-rmse:230.90798\teval-rmse:230.90798\n",
      "[892]\ttrain-rmse:230.05189\teval-rmse:230.05189\n",
      "[893]\ttrain-rmse:229.40445\teval-rmse:229.40445\n",
      "[894]\ttrain-rmse:228.51444\teval-rmse:228.51444\n",
      "[895]\ttrain-rmse:227.69056\teval-rmse:227.69056\n",
      "[896]\ttrain-rmse:226.80045\teval-rmse:226.80045\n",
      "[897]\ttrain-rmse:225.91397\teval-rmse:225.91397\n",
      "[898]\ttrain-rmse:225.13784\teval-rmse:225.13784\n",
      "[899]\ttrain-rmse:224.37383\teval-rmse:224.37383\n",
      "[900]\ttrain-rmse:223.51543\teval-rmse:223.51543\n",
      "[901]\ttrain-rmse:222.81794\teval-rmse:222.81794\n",
      "[902]\ttrain-rmse:222.15529\teval-rmse:222.15529\n",
      "[903]\ttrain-rmse:221.30536\teval-rmse:221.30536\n",
      "[904]\ttrain-rmse:220.62933\teval-rmse:220.62933\n",
      "[905]\ttrain-rmse:219.95393\teval-rmse:219.95393\n",
      "[906]\ttrain-rmse:219.14099\teval-rmse:219.14099\n",
      "[907]\ttrain-rmse:218.49794\teval-rmse:218.49794\n",
      "[908]\ttrain-rmse:217.72316\teval-rmse:217.72316\n",
      "[909]\ttrain-rmse:216.94123\teval-rmse:216.94123\n",
      "[910]\ttrain-rmse:216.17242\teval-rmse:216.17242\n",
      "[911]\ttrain-rmse:215.47042\teval-rmse:215.47042\n",
      "[912]\ttrain-rmse:214.70031\teval-rmse:214.70031\n",
      "[913]\ttrain-rmse:214.03608\teval-rmse:214.03608\n",
      "[914]\ttrain-rmse:213.33623\teval-rmse:213.33623\n",
      "[915]\ttrain-rmse:212.61695\teval-rmse:212.61695\n",
      "[916]\ttrain-rmse:211.82452\teval-rmse:211.82452\n",
      "[917]\ttrain-rmse:211.08698\teval-rmse:211.08698\n",
      "[918]\ttrain-rmse:210.35968\teval-rmse:210.35968\n",
      "[919]\ttrain-rmse:209.61597\teval-rmse:209.61597\n",
      "[920]\ttrain-rmse:208.95438\teval-rmse:208.95438\n",
      "[921]\ttrain-rmse:208.31107\teval-rmse:208.31107\n",
      "[922]\ttrain-rmse:207.52795\teval-rmse:207.52795\n",
      "[923]\ttrain-rmse:206.96977\teval-rmse:206.96977\n",
      "[924]\ttrain-rmse:206.16121\teval-rmse:206.16121\n",
      "[925]\ttrain-rmse:205.64706\teval-rmse:205.64706\n",
      "[926]\ttrain-rmse:204.99332\teval-rmse:204.99332\n",
      "[927]\ttrain-rmse:204.19126\teval-rmse:204.19126\n",
      "[928]\ttrain-rmse:203.58390\teval-rmse:203.58390\n",
      "[929]\ttrain-rmse:202.92779\teval-rmse:202.92779\n",
      "[930]\ttrain-rmse:202.29097\teval-rmse:202.29097\n",
      "[931]\ttrain-rmse:201.60577\teval-rmse:201.60577\n",
      "[932]\ttrain-rmse:200.98772\teval-rmse:200.98772\n",
      "[933]\ttrain-rmse:200.27128\teval-rmse:200.27128\n",
      "[934]\ttrain-rmse:199.61960\teval-rmse:199.61960\n",
      "[935]\ttrain-rmse:198.95970\teval-rmse:198.95970\n",
      "[936]\ttrain-rmse:198.03728\teval-rmse:198.03728\n",
      "[937]\ttrain-rmse:197.35103\teval-rmse:197.35103\n",
      "[938]\ttrain-rmse:196.55777\teval-rmse:196.55777\n",
      "[939]\ttrain-rmse:195.91563\teval-rmse:195.91563\n",
      "[940]\ttrain-rmse:195.18013\teval-rmse:195.18013\n",
      "[941]\ttrain-rmse:194.53072\teval-rmse:194.53072\n",
      "[942]\ttrain-rmse:193.89641\teval-rmse:193.89641\n",
      "[943]\ttrain-rmse:193.26789\teval-rmse:193.26789\n",
      "[944]\ttrain-rmse:192.69495\teval-rmse:192.69495\n",
      "[945]\ttrain-rmse:191.96264\teval-rmse:191.96264\n",
      "[946]\ttrain-rmse:191.27279\teval-rmse:191.27279\n",
      "[947]\ttrain-rmse:190.59873\teval-rmse:190.59873\n",
      "[948]\ttrain-rmse:190.02150\teval-rmse:190.02150\n",
      "[949]\ttrain-rmse:189.33688\teval-rmse:189.33688\n",
      "[950]\ttrain-rmse:188.64036\teval-rmse:188.64036\n",
      "[951]\ttrain-rmse:187.95215\teval-rmse:187.95215\n",
      "[952]\ttrain-rmse:187.36884\teval-rmse:187.36884\n",
      "[953]\ttrain-rmse:186.74864\teval-rmse:186.74864\n",
      "[954]\ttrain-rmse:186.11068\teval-rmse:186.11068\n",
      "[955]\ttrain-rmse:185.49224\teval-rmse:185.49224\n",
      "[956]\ttrain-rmse:184.84719\teval-rmse:184.84719\n",
      "[957]\ttrain-rmse:184.20420\teval-rmse:184.20420\n",
      "[958]\ttrain-rmse:183.54580\teval-rmse:183.54580\n",
      "[959]\ttrain-rmse:182.98093\teval-rmse:182.98093\n",
      "[960]\ttrain-rmse:182.36205\teval-rmse:182.36205\n",
      "[961]\ttrain-rmse:181.78964\teval-rmse:181.78964\n",
      "[962]\ttrain-rmse:181.14901\teval-rmse:181.14901\n",
      "[963]\ttrain-rmse:180.60305\teval-rmse:180.60305\n",
      "[964]\ttrain-rmse:179.91468\teval-rmse:179.91468\n",
      "[965]\ttrain-rmse:179.33747\teval-rmse:179.33747\n",
      "[966]\ttrain-rmse:178.79903\teval-rmse:178.79903\n",
      "[967]\ttrain-rmse:178.18898\teval-rmse:178.18898\n",
      "[968]\ttrain-rmse:177.57828\teval-rmse:177.57828\n",
      "[969]\ttrain-rmse:177.01374\teval-rmse:177.01374\n",
      "[970]\ttrain-rmse:176.34745\teval-rmse:176.34745\n",
      "[971]\ttrain-rmse:175.80851\teval-rmse:175.80851\n",
      "[972]\ttrain-rmse:175.29768\teval-rmse:175.29768\n",
      "[973]\ttrain-rmse:174.85957\teval-rmse:174.85957\n",
      "[974]\ttrain-rmse:174.32442\teval-rmse:174.32442\n",
      "[975]\ttrain-rmse:173.72206\teval-rmse:173.72206\n",
      "[976]\ttrain-rmse:173.17860\teval-rmse:173.17860\n",
      "[977]\ttrain-rmse:172.69439\teval-rmse:172.69439\n",
      "[978]\ttrain-rmse:172.12558\teval-rmse:172.12558\n",
      "[979]\ttrain-rmse:171.52970\teval-rmse:171.52970\n",
      "[980]\ttrain-rmse:170.98181\teval-rmse:170.98181\n",
      "[981]\ttrain-rmse:170.42935\teval-rmse:170.42935\n",
      "[982]\ttrain-rmse:169.92439\teval-rmse:169.92439\n",
      "[983]\ttrain-rmse:169.32261\teval-rmse:169.32261\n",
      "[984]\ttrain-rmse:168.70902\teval-rmse:168.70902\n",
      "[985]\ttrain-rmse:168.08230\teval-rmse:168.08230\n",
      "[986]\ttrain-rmse:167.47169\teval-rmse:167.47169\n",
      "[987]\ttrain-rmse:166.85676\teval-rmse:166.85676\n",
      "[988]\ttrain-rmse:166.29497\teval-rmse:166.29497\n",
      "[989]\ttrain-rmse:165.85373\teval-rmse:165.85373\n",
      "[990]\ttrain-rmse:165.36034\teval-rmse:165.36034\n",
      "[991]\ttrain-rmse:164.81417\teval-rmse:164.81417\n",
      "[992]\ttrain-rmse:164.32874\teval-rmse:164.32874\n",
      "[993]\ttrain-rmse:163.74610\teval-rmse:163.74610\n",
      "[994]\ttrain-rmse:163.17272\teval-rmse:163.17272\n",
      "[995]\ttrain-rmse:162.65798\teval-rmse:162.65798\n",
      "[996]\ttrain-rmse:162.20104\teval-rmse:162.20104\n",
      "[997]\ttrain-rmse:161.70190\teval-rmse:161.70190\n",
      "[998]\ttrain-rmse:161.13454\teval-rmse:161.13454\n",
      "[999]\ttrain-rmse:160.56464\teval-rmse:160.56464\n",
      "[1000]\ttrain-rmse:160.00335\teval-rmse:160.00335\n",
      "[1001]\ttrain-rmse:159.48056\teval-rmse:159.48056\n",
      "[1002]\ttrain-rmse:158.87184\teval-rmse:158.87184\n",
      "[1003]\ttrain-rmse:158.37373\teval-rmse:158.37373\n",
      "[1004]\ttrain-rmse:157.81548\teval-rmse:157.81548\n",
      "[1005]\ttrain-rmse:157.32109\teval-rmse:157.32109\n",
      "[1006]\ttrain-rmse:156.86254\teval-rmse:156.86254\n",
      "[1007]\ttrain-rmse:156.25283\teval-rmse:156.25283\n",
      "[1008]\ttrain-rmse:155.82670\teval-rmse:155.82670\n",
      "[1009]\ttrain-rmse:155.40542\teval-rmse:155.40542\n",
      "[1010]\ttrain-rmse:154.93035\teval-rmse:154.93035\n",
      "[1011]\ttrain-rmse:154.41958\teval-rmse:154.41958\n",
      "[1012]\ttrain-rmse:153.90938\teval-rmse:153.90938\n",
      "[1013]\ttrain-rmse:153.48037\teval-rmse:153.48037\n",
      "[1014]\ttrain-rmse:153.05491\teval-rmse:153.05491\n",
      "[1015]\ttrain-rmse:152.46245\teval-rmse:152.46245\n",
      "[1016]\ttrain-rmse:151.90135\teval-rmse:151.90135\n",
      "[1017]\ttrain-rmse:151.42694\teval-rmse:151.42694\n",
      "[1018]\ttrain-rmse:150.99120\teval-rmse:150.99120\n",
      "[1019]\ttrain-rmse:150.44990\teval-rmse:150.44990\n",
      "[1020]\ttrain-rmse:150.02667\teval-rmse:150.02667\n",
      "[1021]\ttrain-rmse:149.54630\teval-rmse:149.54630\n",
      "[1022]\ttrain-rmse:149.06124\teval-rmse:149.06124\n",
      "[1023]\ttrain-rmse:148.63162\teval-rmse:148.63162\n",
      "[1024]\ttrain-rmse:148.11780\teval-rmse:148.11780\n",
      "[1025]\ttrain-rmse:147.60937\teval-rmse:147.60937\n",
      "[1026]\ttrain-rmse:147.14536\teval-rmse:147.14536\n",
      "[1027]\ttrain-rmse:146.71437\teval-rmse:146.71437\n",
      "[1028]\ttrain-rmse:146.24741\teval-rmse:146.24741\n",
      "[1029]\ttrain-rmse:145.80067\teval-rmse:145.80067\n",
      "[1030]\ttrain-rmse:145.36455\teval-rmse:145.36455\n",
      "[1031]\ttrain-rmse:144.87683\teval-rmse:144.87683\n",
      "[1032]\ttrain-rmse:144.43481\teval-rmse:144.43481\n",
      "[1033]\ttrain-rmse:143.90233\teval-rmse:143.90233\n",
      "[1034]\ttrain-rmse:143.40261\teval-rmse:143.40261\n",
      "[1035]\ttrain-rmse:142.97385\teval-rmse:142.97385\n",
      "[1036]\ttrain-rmse:142.42700\teval-rmse:142.42700\n",
      "[1037]\ttrain-rmse:141.98926\teval-rmse:141.98926\n",
      "[1038]\ttrain-rmse:141.49082\teval-rmse:141.49082\n",
      "[1039]\ttrain-rmse:141.06822\teval-rmse:141.06822\n",
      "[1040]\ttrain-rmse:140.54734\teval-rmse:140.54734\n",
      "[1041]\ttrain-rmse:140.05540\teval-rmse:140.05540\n",
      "[1042]\ttrain-rmse:139.62019\teval-rmse:139.62019\n",
      "[1043]\ttrain-rmse:139.16442\teval-rmse:139.16442\n",
      "[1044]\ttrain-rmse:138.65942\teval-rmse:138.65942\n",
      "[1045]\ttrain-rmse:138.23024\teval-rmse:138.23024\n",
      "[1046]\ttrain-rmse:137.78711\teval-rmse:137.78711\n",
      "[1047]\ttrain-rmse:137.31094\teval-rmse:137.31094\n",
      "[1048]\ttrain-rmse:136.82975\teval-rmse:136.82975\n",
      "[1049]\ttrain-rmse:136.43980\teval-rmse:136.43980\n",
      "[1050]\ttrain-rmse:136.00133\teval-rmse:136.00133\n",
      "[1051]\ttrain-rmse:135.57658\teval-rmse:135.57658\n",
      "[1052]\ttrain-rmse:135.20502\teval-rmse:135.20502\n",
      "[1053]\ttrain-rmse:134.83546\teval-rmse:134.83546\n",
      "[1054]\ttrain-rmse:134.36636\teval-rmse:134.36636\n",
      "[1055]\ttrain-rmse:133.86790\teval-rmse:133.86790\n",
      "[1056]\ttrain-rmse:133.32843\teval-rmse:133.32843\n",
      "[1057]\ttrain-rmse:132.90154\teval-rmse:132.90154\n",
      "[1058]\ttrain-rmse:132.51146\teval-rmse:132.51146\n",
      "[1059]\ttrain-rmse:132.09477\teval-rmse:132.09477\n",
      "[1060]\ttrain-rmse:131.67839\teval-rmse:131.67839\n",
      "[1061]\ttrain-rmse:131.29869\teval-rmse:131.29869\n",
      "[1062]\ttrain-rmse:130.86718\teval-rmse:130.86718\n",
      "[1063]\ttrain-rmse:130.33965\teval-rmse:130.33965\n",
      "[1064]\ttrain-rmse:129.89754\teval-rmse:129.89754\n",
      "[1065]\ttrain-rmse:129.45388\teval-rmse:129.45388\n",
      "[1066]\ttrain-rmse:129.14465\teval-rmse:129.14465\n",
      "[1067]\ttrain-rmse:128.73440\teval-rmse:128.73440\n",
      "[1068]\ttrain-rmse:128.33142\teval-rmse:128.33142\n",
      "[1069]\ttrain-rmse:127.90728\teval-rmse:127.90728\n",
      "[1070]\ttrain-rmse:127.51318\teval-rmse:127.51318\n",
      "[1071]\ttrain-rmse:127.12627\teval-rmse:127.12627\n",
      "[1072]\ttrain-rmse:126.73731\teval-rmse:126.73731\n",
      "[1073]\ttrain-rmse:126.34608\teval-rmse:126.34608\n",
      "[1074]\ttrain-rmse:125.99000\teval-rmse:125.99000\n",
      "[1075]\ttrain-rmse:125.62456\teval-rmse:125.62456\n",
      "[1076]\ttrain-rmse:125.21102\teval-rmse:125.21102\n",
      "[1077]\ttrain-rmse:124.80530\teval-rmse:124.80530\n",
      "[1078]\ttrain-rmse:124.44911\teval-rmse:124.44911\n",
      "[1079]\ttrain-rmse:124.10795\teval-rmse:124.10795\n",
      "[1080]\ttrain-rmse:123.74392\teval-rmse:123.74392\n",
      "[1081]\ttrain-rmse:123.35881\teval-rmse:123.35881\n",
      "[1082]\ttrain-rmse:123.03005\teval-rmse:123.03005\n",
      "[1083]\ttrain-rmse:122.64148\teval-rmse:122.64148\n",
      "[1084]\ttrain-rmse:122.27054\teval-rmse:122.27054\n",
      "[1085]\ttrain-rmse:121.87138\teval-rmse:121.87138\n",
      "[1086]\ttrain-rmse:121.47288\teval-rmse:121.47288\n",
      "[1087]\ttrain-rmse:121.05258\teval-rmse:121.05258\n",
      "[1088]\ttrain-rmse:120.68122\teval-rmse:120.68122\n",
      "[1089]\ttrain-rmse:120.33599\teval-rmse:120.33599\n",
      "[1090]\ttrain-rmse:119.98016\teval-rmse:119.98016\n",
      "[1091]\ttrain-rmse:119.65041\teval-rmse:119.65041\n",
      "[1092]\ttrain-rmse:119.31248\teval-rmse:119.31248\n",
      "[1093]\ttrain-rmse:118.98054\teval-rmse:118.98054\n",
      "[1094]\ttrain-rmse:118.66524\teval-rmse:118.66524\n",
      "[1095]\ttrain-rmse:118.30897\teval-rmse:118.30897\n",
      "[1096]\ttrain-rmse:117.96946\teval-rmse:117.96946\n",
      "[1097]\ttrain-rmse:117.61142\teval-rmse:117.61142\n",
      "[1098]\ttrain-rmse:117.26543\teval-rmse:117.26543\n",
      "[1099]\ttrain-rmse:116.92963\teval-rmse:116.92963\n",
      "[1100]\ttrain-rmse:116.53756\teval-rmse:116.53756\n",
      "[1101]\ttrain-rmse:116.20937\teval-rmse:116.20937\n",
      "[1102]\ttrain-rmse:115.87960\teval-rmse:115.87960\n",
      "[1103]\ttrain-rmse:115.50028\teval-rmse:115.50028\n",
      "[1104]\ttrain-rmse:115.15224\teval-rmse:115.15224\n",
      "[1105]\ttrain-rmse:114.84776\teval-rmse:114.84776\n",
      "[1106]\ttrain-rmse:114.49187\teval-rmse:114.49187\n",
      "[1107]\ttrain-rmse:114.15576\teval-rmse:114.15576\n",
      "[1108]\ttrain-rmse:113.83048\teval-rmse:113.83048\n",
      "[1109]\ttrain-rmse:113.45144\teval-rmse:113.45144\n",
      "[1110]\ttrain-rmse:113.07817\teval-rmse:113.07817\n",
      "[1111]\ttrain-rmse:112.73037\teval-rmse:112.73037\n",
      "[1112]\ttrain-rmse:112.38933\teval-rmse:112.38933\n",
      "[1113]\ttrain-rmse:112.01253\teval-rmse:112.01253\n",
      "[1114]\ttrain-rmse:111.67096\teval-rmse:111.67096\n",
      "[1115]\ttrain-rmse:111.23194\teval-rmse:111.23194\n",
      "[1116]\ttrain-rmse:110.83937\teval-rmse:110.83937\n",
      "[1117]\ttrain-rmse:110.51366\teval-rmse:110.51366\n",
      "[1118]\ttrain-rmse:110.18274\teval-rmse:110.18274\n",
      "[1119]\ttrain-rmse:109.87452\teval-rmse:109.87452\n",
      "[1120]\ttrain-rmse:109.54231\teval-rmse:109.54231\n",
      "[1121]\ttrain-rmse:109.18465\teval-rmse:109.18465\n",
      "[1122]\ttrain-rmse:108.86235\teval-rmse:108.86235\n",
      "[1123]\ttrain-rmse:108.56398\teval-rmse:108.56398\n",
      "[1124]\ttrain-rmse:108.26305\teval-rmse:108.26305\n",
      "[1125]\ttrain-rmse:107.89996\teval-rmse:107.89996\n",
      "[1126]\ttrain-rmse:107.55717\teval-rmse:107.55717\n",
      "[1127]\ttrain-rmse:107.20127\teval-rmse:107.20127\n",
      "[1128]\ttrain-rmse:106.89220\teval-rmse:106.89220\n",
      "[1129]\ttrain-rmse:106.50499\teval-rmse:106.50499\n",
      "[1130]\ttrain-rmse:106.08707\teval-rmse:106.08707\n",
      "[1131]\ttrain-rmse:105.78002\teval-rmse:105.78002\n",
      "[1132]\ttrain-rmse:105.48776\teval-rmse:105.48776\n",
      "[1133]\ttrain-rmse:105.20735\teval-rmse:105.20735\n",
      "[1134]\ttrain-rmse:104.82161\teval-rmse:104.82161\n",
      "[1135]\ttrain-rmse:104.47447\teval-rmse:104.47447\n",
      "[1136]\ttrain-rmse:104.10026\teval-rmse:104.10026\n",
      "[1137]\ttrain-rmse:103.78502\teval-rmse:103.78502\n",
      "[1138]\ttrain-rmse:103.43502\teval-rmse:103.43502\n",
      "[1139]\ttrain-rmse:103.12792\teval-rmse:103.12792\n",
      "[1140]\ttrain-rmse:102.77270\teval-rmse:102.77270\n",
      "[1141]\ttrain-rmse:102.40196\teval-rmse:102.40196\n",
      "[1142]\ttrain-rmse:102.11158\teval-rmse:102.11158\n",
      "[1143]\ttrain-rmse:101.77410\teval-rmse:101.77410\n",
      "[1144]\ttrain-rmse:101.43657\teval-rmse:101.43657\n",
      "[1145]\ttrain-rmse:101.09071\teval-rmse:101.09071\n",
      "[1146]\ttrain-rmse:100.76100\teval-rmse:100.76100\n",
      "[1147]\ttrain-rmse:100.41871\teval-rmse:100.41871\n",
      "[1148]\ttrain-rmse:100.09712\teval-rmse:100.09712\n",
      "[1149]\ttrain-rmse:99.79043\teval-rmse:99.79043\n",
      "[1150]\ttrain-rmse:99.49321\teval-rmse:99.49321\n",
      "[1151]\ttrain-rmse:99.23185\teval-rmse:99.23185\n",
      "[1152]\ttrain-rmse:98.92548\teval-rmse:98.92548\n",
      "[1153]\ttrain-rmse:98.62004\teval-rmse:98.62004\n",
      "[1154]\ttrain-rmse:98.31049\teval-rmse:98.31049\n",
      "[1155]\ttrain-rmse:97.97366\teval-rmse:97.97366\n",
      "[1156]\ttrain-rmse:97.65498\teval-rmse:97.65498\n",
      "[1157]\ttrain-rmse:97.36736\teval-rmse:97.36736\n",
      "[1158]\ttrain-rmse:97.00631\teval-rmse:97.00631\n",
      "[1159]\ttrain-rmse:96.68189\teval-rmse:96.68189\n",
      "[1160]\ttrain-rmse:96.43364\teval-rmse:96.43364\n",
      "[1161]\ttrain-rmse:96.17774\teval-rmse:96.17774\n",
      "[1162]\ttrain-rmse:95.92277\teval-rmse:95.92277\n",
      "[1163]\ttrain-rmse:95.56508\teval-rmse:95.56508\n",
      "[1164]\ttrain-rmse:95.24988\teval-rmse:95.24988\n",
      "[1165]\ttrain-rmse:94.93481\teval-rmse:94.93481\n",
      "[1166]\ttrain-rmse:94.59603\teval-rmse:94.59603\n",
      "[1167]\ttrain-rmse:94.24618\teval-rmse:94.24618\n",
      "[1168]\ttrain-rmse:93.91752\teval-rmse:93.91752\n",
      "[1169]\ttrain-rmse:93.58821\teval-rmse:93.58821\n",
      "[1170]\ttrain-rmse:93.34542\teval-rmse:93.34542\n",
      "[1171]\ttrain-rmse:93.01194\teval-rmse:93.01194\n",
      "[1172]\ttrain-rmse:92.62432\teval-rmse:92.62432\n",
      "[1173]\ttrain-rmse:92.29101\teval-rmse:92.29101\n",
      "[1174]\ttrain-rmse:92.01005\teval-rmse:92.01005\n",
      "[1175]\ttrain-rmse:91.75978\teval-rmse:91.75978\n",
      "[1176]\ttrain-rmse:91.48424\teval-rmse:91.48424\n",
      "[1177]\ttrain-rmse:91.17649\teval-rmse:91.17649\n",
      "[1178]\ttrain-rmse:90.89934\teval-rmse:90.89934\n",
      "[1179]\ttrain-rmse:90.58697\teval-rmse:90.58697\n",
      "[1180]\ttrain-rmse:90.33550\teval-rmse:90.33550\n",
      "[1181]\ttrain-rmse:90.05322\teval-rmse:90.05322\n",
      "[1182]\ttrain-rmse:89.77147\teval-rmse:89.77147\n",
      "[1183]\ttrain-rmse:89.52324\teval-rmse:89.52324\n",
      "[1184]\ttrain-rmse:89.22696\teval-rmse:89.22696\n",
      "[1185]\ttrain-rmse:88.92484\teval-rmse:88.92484\n",
      "[1186]\ttrain-rmse:88.67247\teval-rmse:88.67247\n",
      "[1187]\ttrain-rmse:88.39424\teval-rmse:88.39424\n",
      "[1188]\ttrain-rmse:88.14977\teval-rmse:88.14977\n",
      "[1189]\ttrain-rmse:87.87898\teval-rmse:87.87898\n",
      "[1190]\ttrain-rmse:87.65427\teval-rmse:87.65427\n",
      "[1191]\ttrain-rmse:87.39712\teval-rmse:87.39712\n",
      "[1192]\ttrain-rmse:87.05475\teval-rmse:87.05475\n",
      "[1193]\ttrain-rmse:86.80292\teval-rmse:86.80292\n",
      "[1194]\ttrain-rmse:86.51018\teval-rmse:86.51018\n",
      "[1195]\ttrain-rmse:86.23000\teval-rmse:86.23000\n",
      "[1196]\ttrain-rmse:85.95794\teval-rmse:85.95794\n",
      "[1197]\ttrain-rmse:85.73586\teval-rmse:85.73586\n",
      "[1198]\ttrain-rmse:85.50423\teval-rmse:85.50423\n",
      "[1199]\ttrain-rmse:85.21660\teval-rmse:85.21660\n",
      "[1200]\ttrain-rmse:84.94589\teval-rmse:84.94589\n",
      "[1201]\ttrain-rmse:84.72526\teval-rmse:84.72526\n",
      "[1202]\ttrain-rmse:84.46553\teval-rmse:84.46553\n",
      "[1203]\ttrain-rmse:84.17704\teval-rmse:84.17704\n",
      "[1204]\ttrain-rmse:83.93992\teval-rmse:83.93992\n",
      "[1205]\ttrain-rmse:83.64199\teval-rmse:83.64199\n",
      "[1206]\ttrain-rmse:83.38633\teval-rmse:83.38633\n",
      "[1207]\ttrain-rmse:83.13582\teval-rmse:83.13582\n",
      "[1208]\ttrain-rmse:82.89632\teval-rmse:82.89632\n",
      "[1209]\ttrain-rmse:82.58325\teval-rmse:82.58325\n",
      "[1210]\ttrain-rmse:82.33731\teval-rmse:82.33731\n",
      "[1211]\ttrain-rmse:82.11321\teval-rmse:82.11321\n",
      "[1212]\ttrain-rmse:81.88207\teval-rmse:81.88207\n",
      "[1213]\ttrain-rmse:81.62958\teval-rmse:81.62958\n",
      "[1214]\ttrain-rmse:81.36080\teval-rmse:81.36080\n",
      "[1215]\ttrain-rmse:81.10170\teval-rmse:81.10170\n",
      "[1216]\ttrain-rmse:80.83932\teval-rmse:80.83932\n",
      "[1217]\ttrain-rmse:80.51689\teval-rmse:80.51689\n",
      "[1218]\ttrain-rmse:80.26402\teval-rmse:80.26402\n",
      "[1219]\ttrain-rmse:80.01625\teval-rmse:80.01625\n",
      "[1220]\ttrain-rmse:79.75947\teval-rmse:79.75947\n",
      "[1221]\ttrain-rmse:79.45512\teval-rmse:79.45512\n",
      "[1222]\ttrain-rmse:79.23991\teval-rmse:79.23991\n",
      "[1223]\ttrain-rmse:78.97745\teval-rmse:78.97745\n",
      "[1224]\ttrain-rmse:78.77474\teval-rmse:78.77474\n",
      "[1225]\ttrain-rmse:78.59420\teval-rmse:78.59420\n",
      "[1226]\ttrain-rmse:78.32512\teval-rmse:78.32512\n",
      "[1227]\ttrain-rmse:78.11130\teval-rmse:78.11130\n",
      "[1228]\ttrain-rmse:77.86541\teval-rmse:77.86541\n",
      "[1229]\ttrain-rmse:77.63324\teval-rmse:77.63324\n",
      "[1230]\ttrain-rmse:77.40987\teval-rmse:77.40987\n",
      "[1231]\ttrain-rmse:77.19324\teval-rmse:77.19324\n",
      "[1232]\ttrain-rmse:76.96808\teval-rmse:76.96808\n",
      "[1233]\ttrain-rmse:76.72411\teval-rmse:76.72411\n",
      "[1234]\ttrain-rmse:76.48720\teval-rmse:76.48720\n",
      "[1235]\ttrain-rmse:76.26207\teval-rmse:76.26207\n",
      "[1236]\ttrain-rmse:76.03711\teval-rmse:76.03711\n",
      "[1237]\ttrain-rmse:75.76519\teval-rmse:75.76519\n",
      "[1238]\ttrain-rmse:75.57292\teval-rmse:75.57292\n",
      "[1239]\ttrain-rmse:75.37221\teval-rmse:75.37221\n",
      "[1240]\ttrain-rmse:75.16532\teval-rmse:75.16532\n",
      "[1241]\ttrain-rmse:74.93216\teval-rmse:74.93216\n",
      "[1242]\ttrain-rmse:74.69024\teval-rmse:74.69024\n",
      "[1243]\ttrain-rmse:74.43321\teval-rmse:74.43321\n",
      "[1244]\ttrain-rmse:74.20412\teval-rmse:74.20412\n",
      "[1245]\ttrain-rmse:74.04161\teval-rmse:74.04161\n",
      "[1246]\ttrain-rmse:73.83638\teval-rmse:73.83638\n",
      "[1247]\ttrain-rmse:73.58495\teval-rmse:73.58495\n",
      "[1248]\ttrain-rmse:73.33360\teval-rmse:73.33360\n",
      "[1249]\ttrain-rmse:73.09501\teval-rmse:73.09501\n",
      "[1250]\ttrain-rmse:72.87506\teval-rmse:72.87506\n",
      "[1251]\ttrain-rmse:72.63984\teval-rmse:72.63984\n",
      "[1252]\ttrain-rmse:72.44723\teval-rmse:72.44723\n",
      "[1253]\ttrain-rmse:72.25461\teval-rmse:72.25461\n",
      "[1254]\ttrain-rmse:72.01809\teval-rmse:72.01809\n",
      "[1255]\ttrain-rmse:71.82568\teval-rmse:71.82568\n",
      "[1256]\ttrain-rmse:71.61652\teval-rmse:71.61652\n",
      "[1257]\ttrain-rmse:71.40015\teval-rmse:71.40015\n",
      "[1258]\ttrain-rmse:71.18640\teval-rmse:71.18640\n",
      "[1259]\ttrain-rmse:71.01538\teval-rmse:71.01538\n",
      "[1260]\ttrain-rmse:70.79726\teval-rmse:70.79726\n",
      "[1261]\ttrain-rmse:70.58629\teval-rmse:70.58629\n",
      "[1262]\ttrain-rmse:70.36069\teval-rmse:70.36069\n",
      "[1263]\ttrain-rmse:70.07970\teval-rmse:70.07970\n",
      "[1264]\ttrain-rmse:69.86453\teval-rmse:69.86453\n",
      "[1265]\ttrain-rmse:69.64373\teval-rmse:69.64373\n",
      "[1266]\ttrain-rmse:69.39387\teval-rmse:69.39387\n",
      "[1267]\ttrain-rmse:69.17135\teval-rmse:69.17135\n",
      "[1268]\ttrain-rmse:68.92763\teval-rmse:68.92763\n",
      "[1269]\ttrain-rmse:68.69001\teval-rmse:68.69001\n",
      "[1270]\ttrain-rmse:68.50906\teval-rmse:68.50906\n",
      "[1271]\ttrain-rmse:68.29778\teval-rmse:68.29778\n",
      "[1272]\ttrain-rmse:68.12178\teval-rmse:68.12178\n",
      "[1273]\ttrain-rmse:67.88533\teval-rmse:67.88533\n",
      "[1274]\ttrain-rmse:67.68831\teval-rmse:67.68831\n",
      "[1275]\ttrain-rmse:67.51822\teval-rmse:67.51822\n",
      "[1276]\ttrain-rmse:67.29819\teval-rmse:67.29819\n",
      "[1277]\ttrain-rmse:67.10017\teval-rmse:67.10017\n",
      "[1278]\ttrain-rmse:66.86252\teval-rmse:66.86252\n",
      "[1279]\ttrain-rmse:66.65614\teval-rmse:66.65614\n",
      "[1280]\ttrain-rmse:66.42528\teval-rmse:66.42528\n",
      "[1281]\ttrain-rmse:66.20753\teval-rmse:66.20753\n",
      "[1282]\ttrain-rmse:66.02673\teval-rmse:66.02673\n",
      "[1283]\ttrain-rmse:65.83218\teval-rmse:65.83218\n",
      "[1284]\ttrain-rmse:65.63001\teval-rmse:65.63001\n",
      "[1285]\ttrain-rmse:65.45236\teval-rmse:65.45236\n",
      "[1286]\ttrain-rmse:65.29991\teval-rmse:65.29991\n",
      "[1287]\ttrain-rmse:65.08467\teval-rmse:65.08467\n",
      "[1288]\ttrain-rmse:64.93860\teval-rmse:64.93860\n",
      "[1289]\ttrain-rmse:64.74523\teval-rmse:64.74523\n",
      "[1290]\ttrain-rmse:64.55308\teval-rmse:64.55308\n",
      "[1291]\ttrain-rmse:64.32493\teval-rmse:64.32493\n",
      "[1292]\ttrain-rmse:64.09604\teval-rmse:64.09604\n",
      "[1293]\ttrain-rmse:63.88496\teval-rmse:63.88496\n",
      "[1294]\ttrain-rmse:63.71637\teval-rmse:63.71637\n",
      "[1295]\ttrain-rmse:63.47484\teval-rmse:63.47484\n",
      "[1296]\ttrain-rmse:63.29848\teval-rmse:63.29848\n",
      "[1297]\ttrain-rmse:63.08583\teval-rmse:63.08583\n",
      "[1298]\ttrain-rmse:62.92024\teval-rmse:62.92024\n",
      "[1299]\ttrain-rmse:62.72093\teval-rmse:62.72093\n",
      "[1300]\ttrain-rmse:62.49653\teval-rmse:62.49653\n",
      "[1301]\ttrain-rmse:62.35729\teval-rmse:62.35729\n",
      "[1302]\ttrain-rmse:62.19957\teval-rmse:62.19957\n",
      "[1303]\ttrain-rmse:61.98062\teval-rmse:61.98062\n",
      "[1304]\ttrain-rmse:61.80655\teval-rmse:61.80655\n",
      "[1305]\ttrain-rmse:61.63142\teval-rmse:61.63142\n",
      "[1306]\ttrain-rmse:61.43283\teval-rmse:61.43283\n",
      "[1307]\ttrain-rmse:61.24784\teval-rmse:61.24784\n",
      "[1308]\ttrain-rmse:61.03792\teval-rmse:61.03792\n",
      "[1309]\ttrain-rmse:60.87003\teval-rmse:60.87003\n",
      "[1310]\ttrain-rmse:60.67244\teval-rmse:60.67244\n",
      "[1311]\ttrain-rmse:60.51172\teval-rmse:60.51172\n",
      "[1312]\ttrain-rmse:60.31657\teval-rmse:60.31657\n",
      "[1313]\ttrain-rmse:60.13287\teval-rmse:60.13287\n",
      "[1314]\ttrain-rmse:59.95368\teval-rmse:59.95368\n",
      "[1315]\ttrain-rmse:59.75203\teval-rmse:59.75203\n",
      "[1316]\ttrain-rmse:59.55969\teval-rmse:59.55969\n",
      "[1317]\ttrain-rmse:59.38902\teval-rmse:59.38902\n",
      "[1318]\ttrain-rmse:59.19453\teval-rmse:59.19453\n",
      "[1319]\ttrain-rmse:59.02819\teval-rmse:59.02819\n",
      "[1320]\ttrain-rmse:58.86167\teval-rmse:58.86167\n",
      "[1321]\ttrain-rmse:58.64632\teval-rmse:58.64632\n",
      "[1322]\ttrain-rmse:58.48151\teval-rmse:58.48151\n",
      "[1323]\ttrain-rmse:58.27996\teval-rmse:58.27996\n",
      "[1324]\ttrain-rmse:58.11616\teval-rmse:58.11616\n",
      "[1325]\ttrain-rmse:57.95244\teval-rmse:57.95244\n",
      "[1326]\ttrain-rmse:57.80096\teval-rmse:57.80096\n",
      "[1327]\ttrain-rmse:57.62453\teval-rmse:57.62453\n",
      "[1328]\ttrain-rmse:57.47964\teval-rmse:57.47964\n",
      "[1329]\ttrain-rmse:57.30514\teval-rmse:57.30514\n",
      "[1330]\ttrain-rmse:57.14867\teval-rmse:57.14867\n",
      "[1331]\ttrain-rmse:57.00735\teval-rmse:57.00735\n",
      "[1332]\ttrain-rmse:56.84788\teval-rmse:56.84788\n",
      "[1333]\ttrain-rmse:56.67648\teval-rmse:56.67648\n",
      "[1334]\ttrain-rmse:56.50632\teval-rmse:56.50632\n",
      "[1335]\ttrain-rmse:56.34751\teval-rmse:56.34751\n",
      "[1336]\ttrain-rmse:56.20204\teval-rmse:56.20204\n",
      "[1337]\ttrain-rmse:55.99899\teval-rmse:55.99899\n",
      "[1338]\ttrain-rmse:55.85177\teval-rmse:55.85177\n",
      "[1339]\ttrain-rmse:55.66703\teval-rmse:55.66703\n",
      "[1340]\ttrain-rmse:55.52023\teval-rmse:55.52023\n",
      "[1341]\ttrain-rmse:55.30831\teval-rmse:55.30831\n",
      "[1342]\ttrain-rmse:55.12547\teval-rmse:55.12547\n",
      "[1343]\ttrain-rmse:54.95640\teval-rmse:54.95640\n",
      "[1344]\ttrain-rmse:54.77569\teval-rmse:54.77569\n",
      "[1345]\ttrain-rmse:54.59093\teval-rmse:54.59093\n",
      "[1346]\ttrain-rmse:54.44701\teval-rmse:54.44701\n",
      "[1347]\ttrain-rmse:54.28986\teval-rmse:54.28986\n",
      "[1348]\ttrain-rmse:54.16068\teval-rmse:54.16068\n",
      "[1349]\ttrain-rmse:54.01182\teval-rmse:54.01182\n",
      "[1350]\ttrain-rmse:53.82887\teval-rmse:53.82887\n",
      "[1351]\ttrain-rmse:53.67227\teval-rmse:53.67227\n",
      "[1352]\ttrain-rmse:53.52977\teval-rmse:53.52977\n",
      "[1353]\ttrain-rmse:53.37343\teval-rmse:53.37343\n",
      "[1354]\ttrain-rmse:53.18823\teval-rmse:53.18823\n",
      "[1355]\ttrain-rmse:53.01118\teval-rmse:53.01118\n",
      "[1356]\ttrain-rmse:52.83606\teval-rmse:52.83606\n",
      "[1357]\ttrain-rmse:52.67205\teval-rmse:52.67205\n",
      "[1358]\ttrain-rmse:52.52548\teval-rmse:52.52548\n",
      "[1359]\ttrain-rmse:52.37295\teval-rmse:52.37295\n",
      "[1360]\ttrain-rmse:52.18905\teval-rmse:52.18905\n",
      "[1361]\ttrain-rmse:52.03873\teval-rmse:52.03873\n",
      "[1362]\ttrain-rmse:51.90336\teval-rmse:51.90336\n",
      "[1363]\ttrain-rmse:51.72096\teval-rmse:51.72096\n",
      "[1364]\ttrain-rmse:51.56739\teval-rmse:51.56739\n",
      "[1365]\ttrain-rmse:51.43597\teval-rmse:51.43597\n",
      "[1366]\ttrain-rmse:51.26853\teval-rmse:51.26853\n",
      "[1367]\ttrain-rmse:51.11124\teval-rmse:51.11124\n",
      "[1368]\ttrain-rmse:50.96100\teval-rmse:50.96100\n",
      "[1369]\ttrain-rmse:50.77537\teval-rmse:50.77537\n",
      "[1370]\ttrain-rmse:50.62250\teval-rmse:50.62250\n",
      "[1371]\ttrain-rmse:50.48106\teval-rmse:50.48106\n",
      "[1372]\ttrain-rmse:50.33339\teval-rmse:50.33339\n",
      "[1373]\ttrain-rmse:50.20347\teval-rmse:50.20347\n",
      "[1374]\ttrain-rmse:50.06439\teval-rmse:50.06439\n",
      "[1375]\ttrain-rmse:49.92010\teval-rmse:49.92010\n",
      "[1376]\ttrain-rmse:49.76077\teval-rmse:49.76077\n",
      "[1377]\ttrain-rmse:49.61554\teval-rmse:49.61554\n",
      "[1378]\ttrain-rmse:49.48340\teval-rmse:49.48340\n",
      "[1379]\ttrain-rmse:49.29506\teval-rmse:49.29506\n",
      "[1380]\ttrain-rmse:49.14966\teval-rmse:49.14966\n",
      "[1381]\ttrain-rmse:48.98746\teval-rmse:48.98746\n",
      "[1382]\ttrain-rmse:48.84255\teval-rmse:48.84255\n",
      "[1383]\ttrain-rmse:48.69944\teval-rmse:48.69944\n",
      "[1384]\ttrain-rmse:48.56303\teval-rmse:48.56303\n",
      "[1385]\ttrain-rmse:48.42618\teval-rmse:48.42618\n",
      "[1386]\ttrain-rmse:48.28295\teval-rmse:48.28295\n",
      "[1387]\ttrain-rmse:48.10382\teval-rmse:48.10382\n",
      "[1388]\ttrain-rmse:47.96239\teval-rmse:47.96239\n",
      "[1389]\ttrain-rmse:47.83995\teval-rmse:47.83995\n",
      "[1390]\ttrain-rmse:47.69245\teval-rmse:47.69245\n",
      "[1391]\ttrain-rmse:47.57332\teval-rmse:47.57332\n",
      "[1392]\ttrain-rmse:47.42602\teval-rmse:47.42602\n",
      "[1393]\ttrain-rmse:47.29217\teval-rmse:47.29217\n",
      "[1394]\ttrain-rmse:47.13957\teval-rmse:47.13957\n",
      "[1395]\ttrain-rmse:47.02146\teval-rmse:47.02146\n",
      "[1396]\ttrain-rmse:46.87666\teval-rmse:46.87666\n",
      "[1397]\ttrain-rmse:46.72262\teval-rmse:46.72262\n",
      "[1398]\ttrain-rmse:46.57932\teval-rmse:46.57932\n",
      "[1399]\ttrain-rmse:46.46237\teval-rmse:46.46237\n",
      "[1400]\ttrain-rmse:46.34506\teval-rmse:46.34506\n",
      "[1401]\ttrain-rmse:46.20215\teval-rmse:46.20215\n",
      "[1402]\ttrain-rmse:46.08116\teval-rmse:46.08116\n",
      "[1403]\ttrain-rmse:45.95096\teval-rmse:45.95096\n",
      "[1404]\ttrain-rmse:45.81591\teval-rmse:45.81591\n",
      "[1405]\ttrain-rmse:45.64749\teval-rmse:45.64749\n",
      "[1406]\ttrain-rmse:45.50667\teval-rmse:45.50667\n",
      "[1407]\ttrain-rmse:45.38292\teval-rmse:45.38292\n",
      "[1408]\ttrain-rmse:45.25364\teval-rmse:45.25364\n",
      "[1409]\ttrain-rmse:45.09594\teval-rmse:45.09594\n",
      "[1410]\ttrain-rmse:44.98836\teval-rmse:44.98836\n",
      "[1411]\ttrain-rmse:44.84852\teval-rmse:44.84852\n",
      "[1412]\ttrain-rmse:44.70178\teval-rmse:44.70178\n",
      "[1413]\ttrain-rmse:44.57923\teval-rmse:44.57923\n",
      "[1414]\ttrain-rmse:44.46179\teval-rmse:44.46179\n",
      "[1415]\ttrain-rmse:44.33207\teval-rmse:44.33207\n",
      "[1416]\ttrain-rmse:44.18131\teval-rmse:44.18131\n",
      "[1417]\ttrain-rmse:44.06468\teval-rmse:44.06468\n",
      "[1418]\ttrain-rmse:43.91865\teval-rmse:43.91865\n",
      "[1419]\ttrain-rmse:43.81789\teval-rmse:43.81789\n",
      "[1420]\ttrain-rmse:43.65066\teval-rmse:43.65066\n",
      "[1421]\ttrain-rmse:43.49569\teval-rmse:43.49569\n",
      "[1422]\ttrain-rmse:43.35540\teval-rmse:43.35540\n",
      "[1423]\ttrain-rmse:43.23945\teval-rmse:43.23945\n",
      "[1424]\ttrain-rmse:43.08779\teval-rmse:43.08779\n",
      "[1425]\ttrain-rmse:42.98055\teval-rmse:42.98055\n",
      "[1426]\ttrain-rmse:42.85926\teval-rmse:42.85926\n",
      "[1427]\ttrain-rmse:42.77442\teval-rmse:42.77442\n",
      "[1428]\ttrain-rmse:42.60911\teval-rmse:42.60911\n",
      "[1429]\ttrain-rmse:42.45593\teval-rmse:42.45593\n",
      "[1430]\ttrain-rmse:42.34068\teval-rmse:42.34068\n",
      "[1431]\ttrain-rmse:42.19262\teval-rmse:42.19262\n",
      "[1432]\ttrain-rmse:42.04564\teval-rmse:42.04564\n",
      "[1433]\ttrain-rmse:41.88593\teval-rmse:41.88593\n",
      "[1434]\ttrain-rmse:41.79258\teval-rmse:41.79258\n",
      "[1435]\ttrain-rmse:41.66979\teval-rmse:41.66979\n",
      "[1436]\ttrain-rmse:41.53944\teval-rmse:41.53944\n",
      "[1437]\ttrain-rmse:41.39652\teval-rmse:41.39652\n",
      "[1438]\ttrain-rmse:41.26146\teval-rmse:41.26146\n",
      "[1439]\ttrain-rmse:41.12470\teval-rmse:41.12470\n",
      "[1440]\ttrain-rmse:40.98936\teval-rmse:40.98936\n",
      "[1441]\ttrain-rmse:40.87871\teval-rmse:40.87871\n",
      "[1442]\ttrain-rmse:40.73742\teval-rmse:40.73742\n",
      "[1443]\ttrain-rmse:40.59546\teval-rmse:40.59546\n",
      "[1444]\ttrain-rmse:40.50262\teval-rmse:40.50262\n",
      "[1445]\ttrain-rmse:40.39987\teval-rmse:40.39987\n",
      "[1446]\ttrain-rmse:40.28436\teval-rmse:40.28436\n",
      "[1447]\ttrain-rmse:40.16352\teval-rmse:40.16352\n",
      "[1448]\ttrain-rmse:40.03872\teval-rmse:40.03872\n",
      "[1449]\ttrain-rmse:39.91496\teval-rmse:39.91496\n",
      "[1450]\ttrain-rmse:39.77226\teval-rmse:39.77226\n",
      "[1451]\ttrain-rmse:39.65463\teval-rmse:39.65463\n",
      "[1452]\ttrain-rmse:39.53636\teval-rmse:39.53636\n",
      "[1453]\ttrain-rmse:39.43063\teval-rmse:39.43063\n",
      "[1454]\ttrain-rmse:39.31576\teval-rmse:39.31576\n",
      "[1455]\ttrain-rmse:39.17246\teval-rmse:39.17246\n",
      "[1456]\ttrain-rmse:39.08144\teval-rmse:39.08144\n",
      "[1457]\ttrain-rmse:38.94437\teval-rmse:38.94437\n",
      "[1458]\ttrain-rmse:38.82977\teval-rmse:38.82977\n",
      "[1459]\ttrain-rmse:38.70964\teval-rmse:38.70964\n",
      "[1460]\ttrain-rmse:38.59527\teval-rmse:38.59527\n",
      "[1461]\ttrain-rmse:38.46165\teval-rmse:38.46165\n",
      "[1462]\ttrain-rmse:38.35959\teval-rmse:38.35959\n",
      "[1463]\ttrain-rmse:38.24271\teval-rmse:38.24271\n",
      "[1464]\ttrain-rmse:38.11916\teval-rmse:38.11916\n",
      "[1465]\ttrain-rmse:37.99974\teval-rmse:37.99974\n",
      "[1466]\ttrain-rmse:37.87926\teval-rmse:37.87926\n",
      "[1467]\ttrain-rmse:37.75718\teval-rmse:37.75718\n",
      "[1468]\ttrain-rmse:37.65891\teval-rmse:37.65891\n",
      "[1469]\ttrain-rmse:37.54007\teval-rmse:37.54007\n",
      "[1470]\ttrain-rmse:37.42359\teval-rmse:37.42359\n",
      "[1471]\ttrain-rmse:37.33768\teval-rmse:37.33768\n",
      "[1472]\ttrain-rmse:37.22120\teval-rmse:37.22120\n",
      "[1473]\ttrain-rmse:37.10518\teval-rmse:37.10518\n",
      "[1474]\ttrain-rmse:36.97197\teval-rmse:36.97197\n",
      "[1475]\ttrain-rmse:36.86445\teval-rmse:36.86445\n",
      "[1476]\ttrain-rmse:36.77398\teval-rmse:36.77398\n",
      "[1477]\ttrain-rmse:36.65897\teval-rmse:36.65897\n",
      "[1478]\ttrain-rmse:36.54347\teval-rmse:36.54347\n",
      "[1479]\ttrain-rmse:36.43811\teval-rmse:36.43811\n",
      "[1480]\ttrain-rmse:36.33417\teval-rmse:36.33417\n",
      "[1481]\ttrain-rmse:36.22620\teval-rmse:36.22620\n",
      "[1482]\ttrain-rmse:36.11055\teval-rmse:36.11055\n",
      "[1483]\ttrain-rmse:35.98825\teval-rmse:35.98825\n",
      "[1484]\ttrain-rmse:35.88711\teval-rmse:35.88711\n",
      "[1485]\ttrain-rmse:35.77648\teval-rmse:35.77648\n",
      "[1486]\ttrain-rmse:35.69081\teval-rmse:35.69081\n",
      "[1487]\ttrain-rmse:35.56264\teval-rmse:35.56264\n",
      "[1488]\ttrain-rmse:35.46592\teval-rmse:35.46592\n",
      "[1489]\ttrain-rmse:35.36935\teval-rmse:35.36935\n",
      "[1490]\ttrain-rmse:35.26689\teval-rmse:35.26689\n",
      "[1491]\ttrain-rmse:35.14994\teval-rmse:35.14994\n",
      "[1492]\ttrain-rmse:35.04241\teval-rmse:35.04241\n",
      "[1493]\ttrain-rmse:34.93748\teval-rmse:34.93748\n",
      "[1494]\ttrain-rmse:34.82758\teval-rmse:34.82758\n",
      "[1495]\ttrain-rmse:34.74102\teval-rmse:34.74102\n",
      "[1496]\ttrain-rmse:34.63794\teval-rmse:34.63794\n",
      "[1497]\ttrain-rmse:34.52862\teval-rmse:34.52862\n",
      "[1498]\ttrain-rmse:34.45257\teval-rmse:34.45257\n",
      "[1499]\ttrain-rmse:34.35376\teval-rmse:34.35376\n",
      "[1500]\ttrain-rmse:34.25944\teval-rmse:34.25944\n",
      "[1501]\ttrain-rmse:34.15283\teval-rmse:34.15283\n",
      "[1502]\ttrain-rmse:34.05467\teval-rmse:34.05467\n",
      "[1503]\ttrain-rmse:33.95420\teval-rmse:33.95420\n",
      "[1504]\ttrain-rmse:33.85156\teval-rmse:33.85156\n",
      "[1505]\ttrain-rmse:33.74297\teval-rmse:33.74297\n",
      "[1506]\ttrain-rmse:33.62956\teval-rmse:33.62956\n",
      "[1507]\ttrain-rmse:33.51887\teval-rmse:33.51887\n",
      "[1508]\ttrain-rmse:33.43742\teval-rmse:33.43742\n",
      "[1509]\ttrain-rmse:33.34039\teval-rmse:33.34039\n",
      "[1510]\ttrain-rmse:33.24122\teval-rmse:33.24122\n",
      "[1511]\ttrain-rmse:33.12314\teval-rmse:33.12314\n",
      "[1512]\ttrain-rmse:33.04085\teval-rmse:33.04085\n",
      "[1513]\ttrain-rmse:32.95877\teval-rmse:32.95877\n",
      "[1514]\ttrain-rmse:32.87537\teval-rmse:32.87537\n",
      "[1515]\ttrain-rmse:32.79055\teval-rmse:32.79055\n",
      "[1516]\ttrain-rmse:32.68842\teval-rmse:32.68842\n",
      "[1517]\ttrain-rmse:32.58304\teval-rmse:32.58304\n",
      "[1518]\ttrain-rmse:32.49024\teval-rmse:32.49024\n",
      "[1519]\ttrain-rmse:32.39545\teval-rmse:32.39545\n",
      "[1520]\ttrain-rmse:32.30482\teval-rmse:32.30482\n",
      "[1521]\ttrain-rmse:32.21279\teval-rmse:32.21279\n",
      "[1522]\ttrain-rmse:32.11422\teval-rmse:32.11422\n",
      "[1523]\ttrain-rmse:32.02254\teval-rmse:32.02254\n",
      "[1524]\ttrain-rmse:31.92243\teval-rmse:31.92243\n",
      "[1525]\ttrain-rmse:31.82909\teval-rmse:31.82909\n",
      "[1526]\ttrain-rmse:31.75959\teval-rmse:31.75959\n",
      "[1527]\ttrain-rmse:31.67620\teval-rmse:31.67620\n",
      "[1528]\ttrain-rmse:31.59459\teval-rmse:31.59459\n",
      "[1529]\ttrain-rmse:31.50582\teval-rmse:31.50582\n",
      "[1530]\ttrain-rmse:31.41315\teval-rmse:31.41315\n",
      "[1531]\ttrain-rmse:31.33987\teval-rmse:31.33987\n",
      "[1532]\ttrain-rmse:31.24600\teval-rmse:31.24600\n",
      "[1533]\ttrain-rmse:31.16017\teval-rmse:31.16017\n",
      "[1534]\ttrain-rmse:31.06252\teval-rmse:31.06252\n",
      "[1535]\ttrain-rmse:30.98468\teval-rmse:30.98468\n",
      "[1536]\ttrain-rmse:30.89645\teval-rmse:30.89645\n",
      "[1537]\ttrain-rmse:30.81484\teval-rmse:30.81484\n",
      "[1538]\ttrain-rmse:30.69802\teval-rmse:30.69802\n",
      "[1539]\ttrain-rmse:30.60888\teval-rmse:30.60888\n",
      "[1540]\ttrain-rmse:30.51253\teval-rmse:30.51253\n",
      "[1541]\ttrain-rmse:30.40372\teval-rmse:30.40372\n",
      "[1542]\ttrain-rmse:30.31086\teval-rmse:30.31086\n",
      "[1543]\ttrain-rmse:30.20956\teval-rmse:30.20956\n",
      "[1544]\ttrain-rmse:30.13006\teval-rmse:30.13006\n",
      "[1545]\ttrain-rmse:30.04453\teval-rmse:30.04453\n",
      "[1546]\ttrain-rmse:29.94642\teval-rmse:29.94642\n",
      "[1547]\ttrain-rmse:29.85643\teval-rmse:29.85643\n",
      "[1548]\ttrain-rmse:29.76011\teval-rmse:29.76011\n",
      "[1549]\ttrain-rmse:29.69402\teval-rmse:29.69402\n",
      "[1550]\ttrain-rmse:29.60608\teval-rmse:29.60608\n",
      "[1551]\ttrain-rmse:29.50923\teval-rmse:29.50923\n",
      "[1552]\ttrain-rmse:29.39023\teval-rmse:29.39023\n",
      "[1553]\ttrain-rmse:29.29443\teval-rmse:29.29443\n",
      "[1554]\ttrain-rmse:29.21400\teval-rmse:29.21400\n",
      "[1555]\ttrain-rmse:29.11839\teval-rmse:29.11839\n",
      "[1556]\ttrain-rmse:29.03728\teval-rmse:29.03728\n",
      "[1557]\ttrain-rmse:28.95099\teval-rmse:28.95099\n",
      "[1558]\ttrain-rmse:28.88036\teval-rmse:28.88036\n",
      "[1559]\ttrain-rmse:28.79880\teval-rmse:28.79880\n",
      "[1560]\ttrain-rmse:28.72501\teval-rmse:28.72501\n",
      "[1561]\ttrain-rmse:28.63856\teval-rmse:28.63856\n",
      "[1562]\ttrain-rmse:28.55297\teval-rmse:28.55297\n",
      "[1563]\ttrain-rmse:28.45934\teval-rmse:28.45934\n",
      "[1564]\ttrain-rmse:28.37011\teval-rmse:28.37011\n",
      "[1565]\ttrain-rmse:28.27881\teval-rmse:28.27881\n",
      "[1566]\ttrain-rmse:28.17062\teval-rmse:28.17062\n",
      "[1567]\ttrain-rmse:28.06498\teval-rmse:28.06498\n",
      "[1568]\ttrain-rmse:27.96866\teval-rmse:27.96866\n",
      "[1569]\ttrain-rmse:27.88401\teval-rmse:27.88401\n",
      "[1570]\ttrain-rmse:27.80026\teval-rmse:27.80026\n",
      "[1571]\ttrain-rmse:27.73390\teval-rmse:27.73390\n",
      "[1572]\ttrain-rmse:27.65366\teval-rmse:27.65366\n",
      "[1573]\ttrain-rmse:27.58512\teval-rmse:27.58512\n",
      "[1574]\ttrain-rmse:27.47986\teval-rmse:27.47986\n",
      "[1575]\ttrain-rmse:27.39388\teval-rmse:27.39388\n",
      "[1576]\ttrain-rmse:27.30810\teval-rmse:27.30810\n",
      "[1577]\ttrain-rmse:27.23113\teval-rmse:27.23113\n",
      "[1578]\ttrain-rmse:27.17073\teval-rmse:27.17073\n",
      "[1579]\ttrain-rmse:27.10828\teval-rmse:27.10828\n",
      "[1580]\ttrain-rmse:27.02807\teval-rmse:27.02807\n",
      "[1581]\ttrain-rmse:26.94261\teval-rmse:26.94261\n",
      "[1582]\ttrain-rmse:26.87662\teval-rmse:26.87662\n",
      "[1583]\ttrain-rmse:26.81807\teval-rmse:26.81807\n",
      "[1584]\ttrain-rmse:26.75284\teval-rmse:26.75284\n",
      "[1585]\ttrain-rmse:26.66732\teval-rmse:26.66732\n",
      "[1586]\ttrain-rmse:26.58523\teval-rmse:26.58523\n",
      "[1587]\ttrain-rmse:26.51594\teval-rmse:26.51594\n",
      "[1588]\ttrain-rmse:26.44527\teval-rmse:26.44527\n",
      "[1589]\ttrain-rmse:26.37524\teval-rmse:26.37524\n",
      "[1590]\ttrain-rmse:26.31239\teval-rmse:26.31239\n",
      "[1591]\ttrain-rmse:26.24763\teval-rmse:26.24763\n",
      "[1592]\ttrain-rmse:26.17521\teval-rmse:26.17521\n",
      "[1593]\ttrain-rmse:26.10944\teval-rmse:26.10944\n",
      "[1594]\ttrain-rmse:26.03934\teval-rmse:26.03934\n",
      "[1595]\ttrain-rmse:25.99430\teval-rmse:25.99430\n",
      "[1596]\ttrain-rmse:25.92856\teval-rmse:25.92856\n",
      "[1597]\ttrain-rmse:25.84418\teval-rmse:25.84418\n",
      "[1598]\ttrain-rmse:25.77189\teval-rmse:25.77189\n",
      "[1599]\ttrain-rmse:25.70296\teval-rmse:25.70296\n",
      "[1600]\ttrain-rmse:25.63737\teval-rmse:25.63737\n",
      "[1601]\ttrain-rmse:25.54115\teval-rmse:25.54115\n",
      "[1602]\ttrain-rmse:25.44748\teval-rmse:25.44748\n",
      "[1603]\ttrain-rmse:25.38151\teval-rmse:25.38151\n",
      "[1604]\ttrain-rmse:25.31822\teval-rmse:25.31822\n",
      "[1605]\ttrain-rmse:25.24104\teval-rmse:25.24104\n",
      "[1606]\ttrain-rmse:25.17074\teval-rmse:25.17074\n",
      "[1607]\ttrain-rmse:25.09460\teval-rmse:25.09460\n",
      "[1608]\ttrain-rmse:25.03022\teval-rmse:25.03022\n",
      "[1609]\ttrain-rmse:24.96979\teval-rmse:24.96979\n",
      "[1610]\ttrain-rmse:24.91348\teval-rmse:24.91348\n",
      "[1611]\ttrain-rmse:24.82413\teval-rmse:24.82413\n",
      "[1612]\ttrain-rmse:24.74322\teval-rmse:24.74322\n",
      "[1613]\ttrain-rmse:24.65962\teval-rmse:24.65962\n",
      "[1614]\ttrain-rmse:24.59726\teval-rmse:24.59726\n",
      "[1615]\ttrain-rmse:24.53141\teval-rmse:24.53141\n",
      "[1616]\ttrain-rmse:24.45985\teval-rmse:24.45985\n",
      "[1617]\ttrain-rmse:24.39370\teval-rmse:24.39370\n",
      "[1618]\ttrain-rmse:24.32604\teval-rmse:24.32604\n",
      "[1619]\ttrain-rmse:24.25940\teval-rmse:24.25940\n",
      "[1620]\ttrain-rmse:24.18010\teval-rmse:24.18010\n",
      "[1621]\ttrain-rmse:24.10891\teval-rmse:24.10891\n",
      "[1622]\ttrain-rmse:24.04033\teval-rmse:24.04033\n",
      "[1623]\ttrain-rmse:23.96192\teval-rmse:23.96192\n",
      "[1624]\ttrain-rmse:23.87191\teval-rmse:23.87191\n",
      "[1625]\ttrain-rmse:23.79214\teval-rmse:23.79214\n",
      "[1626]\ttrain-rmse:23.73679\teval-rmse:23.73679\n",
      "[1627]\ttrain-rmse:23.67005\teval-rmse:23.67005\n",
      "[1628]\ttrain-rmse:23.60005\teval-rmse:23.60005\n",
      "[1629]\ttrain-rmse:23.54170\teval-rmse:23.54170\n",
      "[1630]\ttrain-rmse:23.46145\teval-rmse:23.46145\n",
      "[1631]\ttrain-rmse:23.39732\teval-rmse:23.39732\n",
      "[1632]\ttrain-rmse:23.32728\teval-rmse:23.32728\n",
      "[1633]\ttrain-rmse:23.26868\teval-rmse:23.26868\n",
      "[1634]\ttrain-rmse:23.18389\teval-rmse:23.18389\n",
      "[1635]\ttrain-rmse:23.11209\teval-rmse:23.11209\n",
      "[1636]\ttrain-rmse:23.04696\teval-rmse:23.04696\n",
      "[1637]\ttrain-rmse:22.98106\teval-rmse:22.98106\n",
      "[1638]\ttrain-rmse:22.91101\teval-rmse:22.91101\n",
      "[1639]\ttrain-rmse:22.84426\teval-rmse:22.84426\n",
      "[1640]\ttrain-rmse:22.78232\teval-rmse:22.78232\n",
      "[1641]\ttrain-rmse:22.71670\teval-rmse:22.71670\n",
      "[1642]\ttrain-rmse:22.65655\teval-rmse:22.65655\n",
      "[1643]\ttrain-rmse:22.59069\teval-rmse:22.59069\n",
      "[1644]\ttrain-rmse:22.52917\teval-rmse:22.52917\n",
      "[1645]\ttrain-rmse:22.46900\teval-rmse:22.46900\n",
      "[1646]\ttrain-rmse:22.38408\teval-rmse:22.38408\n",
      "[1647]\ttrain-rmse:22.33205\teval-rmse:22.33205\n",
      "[1648]\ttrain-rmse:22.25649\teval-rmse:22.25649\n",
      "[1649]\ttrain-rmse:22.19254\teval-rmse:22.19254\n",
      "[1650]\ttrain-rmse:22.14246\teval-rmse:22.14246\n",
      "[1651]\ttrain-rmse:22.07851\teval-rmse:22.07851\n",
      "[1652]\ttrain-rmse:22.00728\teval-rmse:22.00728\n",
      "[1653]\ttrain-rmse:21.94971\teval-rmse:21.94971\n",
      "[1654]\ttrain-rmse:21.86706\teval-rmse:21.86706\n",
      "[1655]\ttrain-rmse:21.81219\teval-rmse:21.81219\n",
      "[1656]\ttrain-rmse:21.75002\teval-rmse:21.75002\n",
      "[1657]\ttrain-rmse:21.69380\teval-rmse:21.69380\n",
      "[1658]\ttrain-rmse:21.61785\teval-rmse:21.61785\n",
      "[1659]\ttrain-rmse:21.56913\teval-rmse:21.56913\n",
      "[1660]\ttrain-rmse:21.49753\teval-rmse:21.49753\n",
      "[1661]\ttrain-rmse:21.43867\teval-rmse:21.43867\n",
      "[1662]\ttrain-rmse:21.36600\teval-rmse:21.36600\n",
      "[1663]\ttrain-rmse:21.30301\teval-rmse:21.30301\n",
      "[1664]\ttrain-rmse:21.22311\teval-rmse:21.22311\n",
      "[1665]\ttrain-rmse:21.14784\teval-rmse:21.14784\n",
      "[1666]\ttrain-rmse:21.06998\teval-rmse:21.06998\n",
      "[1667]\ttrain-rmse:21.01087\teval-rmse:21.01087\n",
      "[1668]\ttrain-rmse:20.93833\teval-rmse:20.93833\n",
      "[1669]\ttrain-rmse:20.87554\teval-rmse:20.87554\n",
      "[1670]\ttrain-rmse:20.81255\teval-rmse:20.81255\n",
      "[1671]\ttrain-rmse:20.74925\teval-rmse:20.74925\n",
      "[1672]\ttrain-rmse:20.69142\teval-rmse:20.69142\n",
      "[1673]\ttrain-rmse:20.61667\teval-rmse:20.61667\n",
      "[1674]\ttrain-rmse:20.56336\teval-rmse:20.56336\n",
      "[1675]\ttrain-rmse:20.50328\teval-rmse:20.50328\n",
      "[1676]\ttrain-rmse:20.44844\teval-rmse:20.44844\n",
      "[1677]\ttrain-rmse:20.37970\teval-rmse:20.37970\n",
      "[1678]\ttrain-rmse:20.32725\teval-rmse:20.32725\n",
      "[1679]\ttrain-rmse:20.27343\teval-rmse:20.27343\n",
      "[1680]\ttrain-rmse:20.21581\teval-rmse:20.21581\n",
      "[1681]\ttrain-rmse:20.15984\teval-rmse:20.15984\n",
      "[1682]\ttrain-rmse:20.10794\teval-rmse:20.10794\n",
      "[1683]\ttrain-rmse:20.04890\teval-rmse:20.04890\n",
      "[1684]\ttrain-rmse:19.98791\teval-rmse:19.98791\n",
      "[1685]\ttrain-rmse:19.92059\teval-rmse:19.92059\n",
      "[1686]\ttrain-rmse:19.86062\teval-rmse:19.86062\n",
      "[1687]\ttrain-rmse:19.81351\teval-rmse:19.81351\n",
      "[1688]\ttrain-rmse:19.76399\teval-rmse:19.76399\n",
      "[1689]\ttrain-rmse:19.71878\teval-rmse:19.71878\n",
      "[1690]\ttrain-rmse:19.65350\teval-rmse:19.65350\n",
      "[1691]\ttrain-rmse:19.60332\teval-rmse:19.60332\n",
      "[1692]\ttrain-rmse:19.52956\teval-rmse:19.52956\n",
      "[1693]\ttrain-rmse:19.48555\teval-rmse:19.48555\n",
      "[1694]\ttrain-rmse:19.43674\teval-rmse:19.43674\n",
      "[1695]\ttrain-rmse:19.37988\teval-rmse:19.37988\n",
      "[1696]\ttrain-rmse:19.33165\teval-rmse:19.33165\n",
      "[1697]\ttrain-rmse:19.27685\teval-rmse:19.27685\n",
      "[1698]\ttrain-rmse:19.22495\teval-rmse:19.22495\n",
      "[1699]\ttrain-rmse:19.16903\teval-rmse:19.16903\n",
      "[1700]\ttrain-rmse:19.12339\teval-rmse:19.12339\n",
      "[1701]\ttrain-rmse:19.07490\teval-rmse:19.07490\n",
      "[1702]\ttrain-rmse:19.02590\teval-rmse:19.02590\n",
      "[1703]\ttrain-rmse:18.96838\teval-rmse:18.96838\n",
      "[1704]\ttrain-rmse:18.91369\teval-rmse:18.91369\n",
      "[1705]\ttrain-rmse:18.85850\teval-rmse:18.85850\n",
      "[1706]\ttrain-rmse:18.80475\teval-rmse:18.80475\n",
      "[1707]\ttrain-rmse:18.74667\teval-rmse:18.74667\n",
      "[1708]\ttrain-rmse:18.68683\teval-rmse:18.68683\n",
      "[1709]\ttrain-rmse:18.63472\teval-rmse:18.63472\n",
      "[1710]\ttrain-rmse:18.57503\teval-rmse:18.57503\n",
      "[1711]\ttrain-rmse:18.52804\teval-rmse:18.52804\n",
      "[1712]\ttrain-rmse:18.47934\teval-rmse:18.47934\n",
      "[1713]\ttrain-rmse:18.42968\teval-rmse:18.42968\n",
      "[1714]\ttrain-rmse:18.38452\teval-rmse:18.38452\n",
      "[1715]\ttrain-rmse:18.32382\teval-rmse:18.32382\n",
      "[1716]\ttrain-rmse:18.27162\teval-rmse:18.27162\n",
      "[1717]\ttrain-rmse:18.20971\teval-rmse:18.20971\n",
      "[1718]\ttrain-rmse:18.15747\teval-rmse:18.15747\n",
      "[1719]\ttrain-rmse:18.09961\teval-rmse:18.09961\n",
      "[1720]\ttrain-rmse:18.04771\teval-rmse:18.04771\n",
      "[1721]\ttrain-rmse:17.99997\teval-rmse:17.99997\n",
      "[1722]\ttrain-rmse:17.95110\teval-rmse:17.95110\n",
      "[1723]\ttrain-rmse:17.90602\teval-rmse:17.90602\n",
      "[1724]\ttrain-rmse:17.85112\teval-rmse:17.85112\n",
      "[1725]\ttrain-rmse:17.80536\teval-rmse:17.80536\n",
      "[1726]\ttrain-rmse:17.75207\teval-rmse:17.75207\n",
      "[1727]\ttrain-rmse:17.70742\teval-rmse:17.70742\n",
      "[1728]\ttrain-rmse:17.65624\teval-rmse:17.65624\n",
      "[1729]\ttrain-rmse:17.59984\teval-rmse:17.59984\n",
      "[1730]\ttrain-rmse:17.55810\teval-rmse:17.55810\n",
      "[1731]\ttrain-rmse:17.52042\teval-rmse:17.52042\n",
      "[1732]\ttrain-rmse:17.47608\teval-rmse:17.47608\n",
      "[1733]\ttrain-rmse:17.42951\teval-rmse:17.42951\n",
      "[1734]\ttrain-rmse:17.36103\teval-rmse:17.36103\n",
      "[1735]\ttrain-rmse:17.31229\teval-rmse:17.31229\n",
      "[1736]\ttrain-rmse:17.27381\teval-rmse:17.27381\n",
      "[1737]\ttrain-rmse:17.22626\teval-rmse:17.22626\n",
      "[1738]\ttrain-rmse:17.17558\teval-rmse:17.17558\n",
      "[1739]\ttrain-rmse:17.12633\teval-rmse:17.12633\n",
      "[1740]\ttrain-rmse:17.07297\teval-rmse:17.07297\n",
      "[1741]\ttrain-rmse:17.01617\teval-rmse:17.01617\n",
      "[1742]\ttrain-rmse:16.96463\teval-rmse:16.96463\n",
      "[1743]\ttrain-rmse:16.91935\teval-rmse:16.91935\n",
      "[1744]\ttrain-rmse:16.86175\teval-rmse:16.86175\n",
      "[1745]\ttrain-rmse:16.81852\teval-rmse:16.81852\n",
      "[1746]\ttrain-rmse:16.76528\teval-rmse:16.76528\n",
      "[1747]\ttrain-rmse:16.72892\teval-rmse:16.72892\n",
      "[1748]\ttrain-rmse:16.68901\teval-rmse:16.68901\n",
      "[1749]\ttrain-rmse:16.62738\teval-rmse:16.62738\n",
      "[1750]\ttrain-rmse:16.58367\teval-rmse:16.58367\n",
      "[1751]\ttrain-rmse:16.54405\teval-rmse:16.54405\n",
      "[1752]\ttrain-rmse:16.48891\teval-rmse:16.48891\n",
      "[1753]\ttrain-rmse:16.43897\teval-rmse:16.43897\n",
      "[1754]\ttrain-rmse:16.38667\teval-rmse:16.38667\n",
      "[1755]\ttrain-rmse:16.33467\teval-rmse:16.33467\n",
      "[1756]\ttrain-rmse:16.29428\teval-rmse:16.29428\n",
      "[1757]\ttrain-rmse:16.23639\teval-rmse:16.23639\n",
      "[1758]\ttrain-rmse:16.18474\teval-rmse:16.18474\n",
      "[1759]\ttrain-rmse:16.13301\teval-rmse:16.13301\n",
      "[1760]\ttrain-rmse:16.07924\teval-rmse:16.07924\n",
      "[1761]\ttrain-rmse:16.04266\teval-rmse:16.04266\n",
      "[1762]\ttrain-rmse:15.99589\teval-rmse:15.99589\n",
      "[1763]\ttrain-rmse:15.94655\teval-rmse:15.94655\n",
      "[1764]\ttrain-rmse:15.90512\teval-rmse:15.90512\n",
      "[1765]\ttrain-rmse:15.85541\teval-rmse:15.85541\n",
      "[1766]\ttrain-rmse:15.80460\teval-rmse:15.80460\n",
      "[1767]\ttrain-rmse:15.76500\teval-rmse:15.76500\n",
      "[1768]\ttrain-rmse:15.72356\teval-rmse:15.72356\n",
      "[1769]\ttrain-rmse:15.67645\teval-rmse:15.67645\n",
      "[1770]\ttrain-rmse:15.63115\teval-rmse:15.63115\n",
      "[1771]\ttrain-rmse:15.58512\teval-rmse:15.58512\n",
      "[1772]\ttrain-rmse:15.54648\teval-rmse:15.54648\n",
      "[1773]\ttrain-rmse:15.49748\teval-rmse:15.49748\n",
      "[1774]\ttrain-rmse:15.44677\teval-rmse:15.44677\n",
      "[1775]\ttrain-rmse:15.40769\teval-rmse:15.40769\n",
      "[1776]\ttrain-rmse:15.36417\teval-rmse:15.36417\n",
      "[1777]\ttrain-rmse:15.32610\teval-rmse:15.32610\n",
      "[1778]\ttrain-rmse:15.28222\teval-rmse:15.28222\n",
      "[1779]\ttrain-rmse:15.24586\teval-rmse:15.24586\n",
      "[1780]\ttrain-rmse:15.20366\teval-rmse:15.20366\n",
      "[1781]\ttrain-rmse:15.16619\teval-rmse:15.16619\n",
      "[1782]\ttrain-rmse:15.11690\teval-rmse:15.11690\n",
      "[1783]\ttrain-rmse:15.08317\teval-rmse:15.08317\n",
      "[1784]\ttrain-rmse:15.03080\teval-rmse:15.03080\n",
      "[1785]\ttrain-rmse:14.97134\teval-rmse:14.97134\n",
      "[1786]\ttrain-rmse:14.93765\teval-rmse:14.93765\n",
      "[1787]\ttrain-rmse:14.89697\teval-rmse:14.89697\n",
      "[1788]\ttrain-rmse:14.85702\teval-rmse:14.85702\n",
      "[1789]\ttrain-rmse:14.81783\teval-rmse:14.81783\n",
      "[1790]\ttrain-rmse:14.77995\teval-rmse:14.77995\n",
      "[1791]\ttrain-rmse:14.73184\teval-rmse:14.73184\n",
      "[1792]\ttrain-rmse:14.69841\teval-rmse:14.69841\n",
      "[1793]\ttrain-rmse:14.66061\teval-rmse:14.66061\n",
      "[1794]\ttrain-rmse:14.62260\teval-rmse:14.62260\n",
      "[1795]\ttrain-rmse:14.59481\teval-rmse:14.59481\n",
      "[1796]\ttrain-rmse:14.55460\teval-rmse:14.55460\n",
      "[1797]\ttrain-rmse:14.50982\teval-rmse:14.50982\n",
      "[1798]\ttrain-rmse:14.47263\teval-rmse:14.47263\n",
      "[1799]\ttrain-rmse:14.42703\teval-rmse:14.42703\n",
      "[1800]\ttrain-rmse:14.38962\teval-rmse:14.38962\n",
      "[1801]\ttrain-rmse:14.34496\teval-rmse:14.34496\n",
      "[1802]\ttrain-rmse:14.30051\teval-rmse:14.30051\n",
      "[1803]\ttrain-rmse:14.26102\teval-rmse:14.26102\n",
      "[1804]\ttrain-rmse:14.21272\teval-rmse:14.21272\n",
      "[1805]\ttrain-rmse:14.18233\teval-rmse:14.18233\n",
      "[1806]\ttrain-rmse:14.14428\teval-rmse:14.14428\n",
      "[1807]\ttrain-rmse:14.10408\teval-rmse:14.10408\n",
      "[1808]\ttrain-rmse:14.07061\teval-rmse:14.07061\n",
      "[1809]\ttrain-rmse:14.03355\teval-rmse:14.03355\n",
      "[1810]\ttrain-rmse:13.98311\teval-rmse:13.98311\n",
      "[1811]\ttrain-rmse:13.93777\teval-rmse:13.93777\n",
      "[1812]\ttrain-rmse:13.90070\teval-rmse:13.90070\n",
      "[1813]\ttrain-rmse:13.86138\teval-rmse:13.86138\n",
      "[1814]\ttrain-rmse:13.82551\teval-rmse:13.82551\n",
      "[1815]\ttrain-rmse:13.78340\teval-rmse:13.78340\n",
      "[1816]\ttrain-rmse:13.74417\teval-rmse:13.74417\n",
      "[1817]\ttrain-rmse:13.71082\teval-rmse:13.71082\n",
      "[1818]\ttrain-rmse:13.66422\teval-rmse:13.66422\n",
      "[1819]\ttrain-rmse:13.61451\teval-rmse:13.61451\n",
      "[1820]\ttrain-rmse:13.58578\teval-rmse:13.58578\n",
      "[1821]\ttrain-rmse:13.55827\teval-rmse:13.55827\n",
      "[1822]\ttrain-rmse:13.52100\teval-rmse:13.52100\n",
      "[1823]\ttrain-rmse:13.49125\teval-rmse:13.49125\n",
      "[1824]\ttrain-rmse:13.45408\teval-rmse:13.45408\n",
      "[1825]\ttrain-rmse:13.42326\teval-rmse:13.42326\n",
      "[1826]\ttrain-rmse:13.38246\teval-rmse:13.38246\n",
      "[1827]\ttrain-rmse:13.34613\teval-rmse:13.34613\n",
      "[1828]\ttrain-rmse:13.31242\teval-rmse:13.31242\n",
      "[1829]\ttrain-rmse:13.28373\teval-rmse:13.28373\n",
      "[1830]\ttrain-rmse:13.24856\teval-rmse:13.24856\n",
      "[1831]\ttrain-rmse:13.21790\teval-rmse:13.21790\n",
      "[1832]\ttrain-rmse:13.19136\teval-rmse:13.19136\n",
      "[1833]\ttrain-rmse:13.15496\teval-rmse:13.15496\n",
      "[1834]\ttrain-rmse:13.11580\teval-rmse:13.11580\n",
      "[1835]\ttrain-rmse:13.07956\teval-rmse:13.07956\n",
      "[1836]\ttrain-rmse:13.04445\teval-rmse:13.04445\n",
      "[1837]\ttrain-rmse:13.01584\teval-rmse:13.01584\n",
      "[1838]\ttrain-rmse:12.96830\teval-rmse:12.96830\n",
      "[1839]\ttrain-rmse:12.92984\teval-rmse:12.92984\n",
      "[1840]\ttrain-rmse:12.89392\teval-rmse:12.89392\n",
      "[1841]\ttrain-rmse:12.85662\teval-rmse:12.85662\n",
      "[1842]\ttrain-rmse:12.81458\teval-rmse:12.81458\n",
      "[1843]\ttrain-rmse:12.77732\teval-rmse:12.77732\n",
      "[1844]\ttrain-rmse:12.73949\teval-rmse:12.73949\n",
      "[1845]\ttrain-rmse:12.70672\teval-rmse:12.70672\n",
      "[1846]\ttrain-rmse:12.67669\teval-rmse:12.67669\n",
      "[1847]\ttrain-rmse:12.65100\teval-rmse:12.65100\n",
      "[1848]\ttrain-rmse:12.61240\teval-rmse:12.61240\n",
      "[1849]\ttrain-rmse:12.58121\teval-rmse:12.58121\n",
      "[1850]\ttrain-rmse:12.55611\teval-rmse:12.55611\n",
      "[1851]\ttrain-rmse:12.52014\teval-rmse:12.52014\n",
      "[1852]\ttrain-rmse:12.48357\teval-rmse:12.48357\n",
      "[1853]\ttrain-rmse:12.45246\teval-rmse:12.45246\n",
      "[1854]\ttrain-rmse:12.41955\teval-rmse:12.41955\n",
      "[1855]\ttrain-rmse:12.38265\teval-rmse:12.38265\n",
      "[1856]\ttrain-rmse:12.35010\teval-rmse:12.35010\n",
      "[1857]\ttrain-rmse:12.32018\teval-rmse:12.32018\n",
      "[1858]\ttrain-rmse:12.29395\teval-rmse:12.29395\n",
      "[1859]\ttrain-rmse:12.25760\teval-rmse:12.25760\n",
      "[1860]\ttrain-rmse:12.22704\teval-rmse:12.22704\n",
      "[1861]\ttrain-rmse:12.19164\teval-rmse:12.19164\n",
      "[1862]\ttrain-rmse:12.16443\teval-rmse:12.16443\n",
      "[1863]\ttrain-rmse:12.13129\teval-rmse:12.13129\n",
      "[1864]\ttrain-rmse:12.10020\teval-rmse:12.10020\n",
      "[1865]\ttrain-rmse:12.06985\teval-rmse:12.06985\n",
      "[1866]\ttrain-rmse:12.03948\teval-rmse:12.03948\n",
      "[1867]\ttrain-rmse:12.00260\teval-rmse:12.00260\n",
      "[1868]\ttrain-rmse:11.96205\teval-rmse:11.96205\n",
      "[1869]\ttrain-rmse:11.92756\teval-rmse:11.92756\n",
      "[1870]\ttrain-rmse:11.90107\teval-rmse:11.90107\n",
      "[1871]\ttrain-rmse:11.86519\teval-rmse:11.86519\n",
      "[1872]\ttrain-rmse:11.83666\teval-rmse:11.83666\n",
      "[1873]\ttrain-rmse:11.80341\teval-rmse:11.80341\n",
      "[1874]\ttrain-rmse:11.76046\teval-rmse:11.76046\n",
      "[1875]\ttrain-rmse:11.73471\teval-rmse:11.73471\n",
      "[1876]\ttrain-rmse:11.69830\teval-rmse:11.69830\n",
      "[1877]\ttrain-rmse:11.65741\teval-rmse:11.65741\n",
      "[1878]\ttrain-rmse:11.62896\teval-rmse:11.62896\n",
      "[1879]\ttrain-rmse:11.60181\teval-rmse:11.60181\n",
      "[1880]\ttrain-rmse:11.57178\teval-rmse:11.57178\n",
      "[1881]\ttrain-rmse:11.54981\teval-rmse:11.54981\n",
      "[1882]\ttrain-rmse:11.51471\teval-rmse:11.51471\n",
      "[1883]\ttrain-rmse:11.48616\teval-rmse:11.48616\n",
      "[1884]\ttrain-rmse:11.45160\teval-rmse:11.45160\n",
      "[1885]\ttrain-rmse:11.41229\teval-rmse:11.41229\n",
      "[1886]\ttrain-rmse:11.38790\teval-rmse:11.38790\n",
      "[1887]\ttrain-rmse:11.35808\teval-rmse:11.35808\n",
      "[1888]\ttrain-rmse:11.31886\teval-rmse:11.31886\n",
      "[1889]\ttrain-rmse:11.29414\teval-rmse:11.29414\n",
      "[1890]\ttrain-rmse:11.26441\teval-rmse:11.26441\n",
      "[1891]\ttrain-rmse:11.23295\teval-rmse:11.23295\n",
      "[1892]\ttrain-rmse:11.20067\teval-rmse:11.20067\n",
      "[1893]\ttrain-rmse:11.16451\teval-rmse:11.16451\n",
      "[1894]\ttrain-rmse:11.13660\teval-rmse:11.13660\n",
      "[1895]\ttrain-rmse:11.10347\teval-rmse:11.10347\n",
      "[1896]\ttrain-rmse:11.07172\teval-rmse:11.07172\n",
      "[1897]\ttrain-rmse:11.04640\teval-rmse:11.04640\n",
      "[1898]\ttrain-rmse:11.01881\teval-rmse:11.01881\n",
      "[1899]\ttrain-rmse:10.99395\teval-rmse:10.99395\n",
      "[1900]\ttrain-rmse:10.95400\teval-rmse:10.95400\n",
      "[1901]\ttrain-rmse:10.92002\teval-rmse:10.92002\n",
      "[1902]\ttrain-rmse:10.88769\teval-rmse:10.88769\n",
      "[1903]\ttrain-rmse:10.85750\teval-rmse:10.85750\n",
      "[1904]\ttrain-rmse:10.83248\teval-rmse:10.83248\n",
      "[1905]\ttrain-rmse:10.80683\teval-rmse:10.80683\n",
      "[1906]\ttrain-rmse:10.77757\teval-rmse:10.77757\n",
      "[1907]\ttrain-rmse:10.75068\teval-rmse:10.75068\n",
      "[1908]\ttrain-rmse:10.71920\teval-rmse:10.71920\n",
      "[1909]\ttrain-rmse:10.69629\teval-rmse:10.69629\n",
      "[1910]\ttrain-rmse:10.66883\teval-rmse:10.66883\n",
      "[1911]\ttrain-rmse:10.63877\teval-rmse:10.63877\n",
      "[1912]\ttrain-rmse:10.61161\teval-rmse:10.61161\n",
      "[1913]\ttrain-rmse:10.58788\teval-rmse:10.58788\n",
      "[1914]\ttrain-rmse:10.56118\teval-rmse:10.56118\n",
      "[1915]\ttrain-rmse:10.52783\teval-rmse:10.52783\n",
      "[1916]\ttrain-rmse:10.50545\teval-rmse:10.50545\n",
      "[1917]\ttrain-rmse:10.47810\teval-rmse:10.47810\n",
      "[1918]\ttrain-rmse:10.44769\teval-rmse:10.44769\n",
      "[1919]\ttrain-rmse:10.42519\teval-rmse:10.42519\n",
      "[1920]\ttrain-rmse:10.39698\teval-rmse:10.39698\n",
      "[1921]\ttrain-rmse:10.37114\teval-rmse:10.37114\n",
      "[1922]\ttrain-rmse:10.34325\teval-rmse:10.34325\n",
      "[1923]\ttrain-rmse:10.32109\teval-rmse:10.32109\n",
      "[1924]\ttrain-rmse:10.29217\teval-rmse:10.29217\n",
      "[1925]\ttrain-rmse:10.25714\teval-rmse:10.25714\n",
      "[1926]\ttrain-rmse:10.22739\teval-rmse:10.22739\n",
      "[1927]\ttrain-rmse:10.20730\teval-rmse:10.20730\n",
      "[1928]\ttrain-rmse:10.18970\teval-rmse:10.18970\n",
      "[1929]\ttrain-rmse:10.16643\teval-rmse:10.16643\n",
      "[1930]\ttrain-rmse:10.14132\teval-rmse:10.14132\n",
      "[1931]\ttrain-rmse:10.12088\teval-rmse:10.12088\n",
      "[1932]\ttrain-rmse:10.09766\teval-rmse:10.09766\n",
      "[1933]\ttrain-rmse:10.07049\teval-rmse:10.07049\n",
      "[1934]\ttrain-rmse:10.04527\teval-rmse:10.04527\n",
      "[1935]\ttrain-rmse:10.02346\teval-rmse:10.02346\n",
      "[1936]\ttrain-rmse:9.99555\teval-rmse:9.99555\n",
      "[1937]\ttrain-rmse:9.96640\teval-rmse:9.96640\n",
      "[1938]\ttrain-rmse:9.94392\teval-rmse:9.94392\n",
      "[1939]\ttrain-rmse:9.91732\teval-rmse:9.91732\n",
      "[1940]\ttrain-rmse:9.89605\teval-rmse:9.89605\n",
      "[1941]\ttrain-rmse:9.87074\teval-rmse:9.87074\n",
      "[1942]\ttrain-rmse:9.84960\teval-rmse:9.84960\n",
      "[1943]\ttrain-rmse:9.82967\teval-rmse:9.82967\n",
      "[1944]\ttrain-rmse:9.80726\teval-rmse:9.80726\n",
      "[1945]\ttrain-rmse:9.78127\teval-rmse:9.78127\n",
      "[1946]\ttrain-rmse:9.76193\teval-rmse:9.76193\n",
      "[1947]\ttrain-rmse:9.73400\teval-rmse:9.73400\n",
      "[1948]\ttrain-rmse:9.71245\teval-rmse:9.71245\n",
      "[1949]\ttrain-rmse:9.68965\teval-rmse:9.68965\n",
      "[1950]\ttrain-rmse:9.66730\teval-rmse:9.66730\n",
      "[1951]\ttrain-rmse:9.64622\teval-rmse:9.64622\n",
      "[1952]\ttrain-rmse:9.61985\teval-rmse:9.61985\n",
      "[1953]\ttrain-rmse:9.59696\teval-rmse:9.59696\n",
      "[1954]\ttrain-rmse:9.57959\teval-rmse:9.57959\n",
      "[1955]\ttrain-rmse:9.56095\teval-rmse:9.56095\n",
      "[1956]\ttrain-rmse:9.53948\teval-rmse:9.53948\n",
      "[1957]\ttrain-rmse:9.51082\teval-rmse:9.51082\n",
      "[1958]\ttrain-rmse:9.48809\teval-rmse:9.48809\n",
      "[1959]\ttrain-rmse:9.46633\teval-rmse:9.46633\n",
      "[1960]\ttrain-rmse:9.44472\teval-rmse:9.44472\n",
      "[1961]\ttrain-rmse:9.42439\teval-rmse:9.42439\n",
      "[1962]\ttrain-rmse:9.40150\teval-rmse:9.40150\n",
      "[1963]\ttrain-rmse:9.37802\teval-rmse:9.37802\n",
      "[1964]\ttrain-rmse:9.35585\teval-rmse:9.35585\n",
      "[1965]\ttrain-rmse:9.33522\teval-rmse:9.33522\n",
      "[1966]\ttrain-rmse:9.31056\teval-rmse:9.31056\n",
      "[1967]\ttrain-rmse:9.28394\teval-rmse:9.28394\n",
      "[1968]\ttrain-rmse:9.26439\teval-rmse:9.26439\n",
      "[1969]\ttrain-rmse:9.24647\teval-rmse:9.24647\n",
      "[1970]\ttrain-rmse:9.22942\teval-rmse:9.22942\n",
      "[1971]\ttrain-rmse:9.20862\teval-rmse:9.20862\n",
      "[1972]\ttrain-rmse:9.18455\teval-rmse:9.18455\n",
      "[1973]\ttrain-rmse:9.16601\teval-rmse:9.16601\n",
      "[1974]\ttrain-rmse:9.14281\teval-rmse:9.14281\n",
      "[1975]\ttrain-rmse:9.11882\teval-rmse:9.11882\n",
      "[1976]\ttrain-rmse:9.09974\teval-rmse:9.09974\n",
      "[1977]\ttrain-rmse:9.07633\teval-rmse:9.07633\n",
      "[1978]\ttrain-rmse:9.05735\teval-rmse:9.05735\n",
      "[1979]\ttrain-rmse:9.03349\teval-rmse:9.03349\n",
      "[1980]\ttrain-rmse:9.01527\teval-rmse:9.01527\n",
      "[1981]\ttrain-rmse:8.99804\teval-rmse:8.99804\n",
      "[1982]\ttrain-rmse:8.97506\teval-rmse:8.97506\n",
      "[1983]\ttrain-rmse:8.95022\teval-rmse:8.95022\n",
      "[1984]\ttrain-rmse:8.92343\teval-rmse:8.92343\n",
      "[1985]\ttrain-rmse:8.90782\teval-rmse:8.90782\n",
      "[1986]\ttrain-rmse:8.88741\teval-rmse:8.88741\n",
      "[1987]\ttrain-rmse:8.86561\teval-rmse:8.86561\n",
      "[1988]\ttrain-rmse:8.84553\teval-rmse:8.84553\n",
      "[1989]\ttrain-rmse:8.82263\teval-rmse:8.82263\n",
      "[1990]\ttrain-rmse:8.80119\teval-rmse:8.80119\n",
      "[1991]\ttrain-rmse:8.77775\teval-rmse:8.77775\n",
      "[1992]\ttrain-rmse:8.75692\teval-rmse:8.75692\n",
      "[1993]\ttrain-rmse:8.73827\teval-rmse:8.73827\n",
      "[1994]\ttrain-rmse:8.71769\teval-rmse:8.71769\n",
      "[1995]\ttrain-rmse:8.69157\teval-rmse:8.69157\n",
      "[1996]\ttrain-rmse:8.67628\teval-rmse:8.67628\n",
      "[1997]\ttrain-rmse:8.65543\teval-rmse:8.65543\n",
      "[1998]\ttrain-rmse:8.63817\teval-rmse:8.63817\n",
      "[1999]\ttrain-rmse:8.61650\teval-rmse:8.61650\n"
     ]
    }
   ],
   "source": [
    "### train models on the entire train set\n",
    "ddata = xgb.DMatrix(data.drop('SalePrice', axis=1), label=data['SalePrice'])\n",
    "lm = LinearRegression()\n",
    "lm.fit(data.drop('SalePrice', axis=1), data['SalePrice'])\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "rf.fit(data.drop('SalePrice', axis=1), data['SalePrice'])\n",
    "results = {}\n",
    "watchlist = [(ddata, 'train'), (ddata, 'eval')]\n",
    "gb = xgb.train(params=gb_params, dtrain=ddata, num_boost_round=2500, evals=watchlist, evals_result = results, early_stopping_rounds=10, verbose_eval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights for DR Stacking: [-1.77070934e-04  1.00017296e+00]\n"
     ]
    }
   ],
   "source": [
    "### Stacking on test set\n",
    "# get train set predictions\n",
    "train_preds = [rf.predict(data.drop('SalePrice', axis=1)), gb.predict(ddata)]\n",
    "ensemble_model = ensemble(train_preds, y_true=data['SalePrice'])\n",
    "\n",
    "# run stacking on test set\n",
    "ids = test['Id']\n",
    "test = merged.iloc[len(data):].drop(columns=['SalePrice'])\n",
    "dtest = xgb.DMatrix(test, label=None)\n",
    "test_pred_rf = rf.predict(test)\n",
    "test_pred_gb = gb.predict(dtest)\n",
    "test_preds = [test_pred_rf, test_pred_gb]\n",
    "final_preds = ensemble_model.predict(np.column_stack(test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1461</td>\n",
       "      <td>128042.391659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1462</td>\n",
       "      <td>156061.916011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1463</td>\n",
       "      <td>187858.107112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1464</td>\n",
       "      <td>190926.487740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1465</td>\n",
       "      <td>192628.985309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>2915</td>\n",
       "      <td>79826.141292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>2916</td>\n",
       "      <td>79921.447020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>2917</td>\n",
       "      <td>165946.924336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>2918</td>\n",
       "      <td>108448.846525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>2919</td>\n",
       "      <td>225011.264275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1459 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id      SalePrice\n",
       "0     1461  128042.391659\n",
       "1     1462  156061.916011\n",
       "2     1463  187858.107112\n",
       "3     1464  190926.487740\n",
       "4     1465  192628.985309\n",
       "...    ...            ...\n",
       "1454  2915   79826.141292\n",
       "1455  2916   79921.447020\n",
       "1456  2917  165946.924336\n",
       "1457  2918  108448.846525\n",
       "1458  2919  225011.264275\n",
       "\n",
       "[1459 rows x 2 columns]"
      ]
     },
     "execution_count": 682,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = pd.DataFrame({'Id': ids, 'SalePrice': final_preds.squeeze()}) \n",
    "output.to_csv('submission.csv', index=False)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### Get the feature importances\n",
    "# importances = pd.Series(rf.feature_importances_, index=train.drop('SalePrice', axis=1).columns)\n",
    "\n",
    "# # Sort the feature importances in descending order\n",
    "# importances_sorted = importances.sort_values(ascending=False)\n",
    "\n",
    "# # Print the sorted feature importances\n",
    "# print(importances_sorted.head(30))\n",
    "\n",
    "# # Select the top 20 features\n",
    "# top_features = importances_sorted.head(30).index\n",
    "\n",
    "# print(top_features)\n",
    "\n",
    "# # # Restrict the dataset to only the top 20 features\n",
    "# # train_top_20 = train[top_20_features]\n",
    "# # val_top_20 = val[top_20_features]\n",
    "\n",
    "# # # Create new instances of the LinearRegression and RandomForestRegressor models\n",
    "# # lm_top_20 = LinearRegression()\n",
    "# # rf_top_20 = RandomForestRegressor(n_estimators=5000, max_depth=20)\n",
    "\n",
    "# # # Fit the models to the training data with the top 20 features\n",
    "# # lm_top_20.fit(train_top_20, train['SalePrice'])\n",
    "# # rf_top_20.fit(train_top_20, train['SalePrice'])\n",
    "\n",
    "# # # Predict on the training data with the top 20 features\n",
    "# # train_pred_lm_top_20 = lm_top_20.predict(train_top_20)\n",
    "# # train_pred_rf_top_20 = rf_top_20.predict(train_top_20)\n",
    "\n",
    "# # # Compute the train RMSE for linear regression and random forest with the top 20 features\n",
    "# # train_rmse_lm_top_20 = np.sqrt(mean_squared_error(train['SalePrice'], train_pred_lm_top_20))\n",
    "# # train_rmse_rf_top_20 = np.sqrt(mean_squared_error(train['SalePrice'], train_pred_rf_top_20))\n",
    "\n",
    "# # # Predict on the validation data with the top 20 features\n",
    "# # val_pred_lm_top_20 = lm_top_20.predict(val_top_20)\n",
    "# # val_pred_rf_top_20 = rf_top_20.predict(val_top_20)\n",
    "\n",
    "# # # Compute the validation RMSE for linear regression and random forest with the top 20 features\n",
    "# # val_rmse_lm_top_20 = np.sqrt(mean_squared_error(val['SalePrice'], val_pred_lm_top_20))\n",
    "# # val_rmse_rf_top_20 = np.sqrt(mean_squared_error(val['SalePrice'], val_pred_rf_top_20))\n",
    "\n",
    "# # # Print the train and validation RMSE for linear regression and random forest with the top 20 features\n",
    "# # print('Linear Regression Train RMSE (Top 20 features):', train_rmse_lm_top_20)\n",
    "# # print('Random Forest Train RMSE (Top 20 features):', train_rmse_rf_top_20)\n",
    "# # print('Linear Regression Validation RMSE (Top 20 features):', val_rmse_lm_top_20)\n",
    "# # print('Random Forest Validation RMSE (Top 20 features):', val_rmse_rf_top_20)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
